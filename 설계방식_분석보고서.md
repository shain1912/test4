# AI 기반 대화형 공공디자인 평가 시스템 설계 방식 분석 보고서

## 전통적 리커트 척도와 AI 인터뷰 방식의 과학적·통계적 비교 분석

---

## 목차

1. [서론](#1-서론)
2. [시스템 설계 아키텍처 분석](#2-시스템-설계-아키텍처-분석)
3. [정보의 밀도: 이산적 범주화와 연속적 의미 보존의 대결](#3-정보의-밀도-이산적-범주화와-연속적-의미-보존의-대결)
4. [확장성: 운영 효율성과 분석적 일반화의 조화](#4-확장성-운영-효율성과-분석적-일반화의-조화)
5. [실증적 분석: 생성적 에이전트와 개인의 고유성 보존](#5-실증적-분석-생성적-에이전트와-개인의-고유성-보존)
6. [과학적·통계적 편향의 전이: 인간의 편향 vs AI의 편향](#6-과학적통계적-편향의-전이-인간의-편향-vs-ai의-편향)
7. [기술적 융합과 응용: NER과 GIS를 통한 데이터 가치 극대화](#7-기술적-융합과-응용-ner과-gis를-통한-데이터-가치-극대화)
8. [수치화 가능성과 과학적 타당성: 핵심 질문에 대한 응답](#8-수치화-가능성과-과학적-타당성-핵심-질문에-대한-응답)
9. [통계적 타당성 검증 세부 방법론](#9-통계적-타당성-검증-세부-방법론)
10. [비교 분석 종합표](#10-비교-분석-종합표)
11. [결론: 데이터의 해상도와 미래의 통찰](#11-결론-데이터의-해상도와-미래의-통찰)
12. [참고문헌](#12-참고문헌)

---

## 1. 서론

### 1.1 연구 배경

인간의 태도, 의견, 그리고 심리적 구성 요소를 측정하고자 하는 노력은 사회과학과 마케팅 조사 분야에서 핵심적인 과제였다. 1932년 렌시스 리커트(Rensis Likert)가 제안한 **리커트 척도(Likert Scale)**는 복잡한 주관적 심리를 정량화 가능한 데이터로 변환하는 표준적인 도구로 자리 잡았다(Likert, 1932). 그러나 최근 대규모 언어 모델(LLM)을 활용한 비정형 대화 방식의 AI 인터뷰가 등장하면서, 기존의 측정 패러다임은 근본적인 변화를 맞이하고 있다.

본 보고서는 부산 글로벌 허브 도시 조성을 위해 개발된 **AI 기반 공공디자인 대화형 평가 시스템**의 설계 방식을 분석하고, 전통적인 체크리스트 방식과 AI 인터뷰 방식의 과학적·통계적 차이점을 **정보의 밀도(Information Density)**와 **확장성(Scalability)**이라는 두 가지 핵심 차원에서 비교 분석하며, 이를 위해 최신 연구 문헌과 통계적 모델을 인용하여 심층적인 통찰을 제공한다.

### 1.2 시스템 개요

본 시스템은 다음과 같은 핵심 기술을 활용한다:

| 구성요소 | 기술 스택 | 역할 |
|---------|----------|------|
| AI 인터뷰어 | LangGraph + GPT-4o | 상태 기반 적응형 대화 수행 |
| 구조화 출력 | Pydantic + Structured Output | 비정형 응답의 정형 데이터 변환 |
| 의미 분석 | OpenAI Embeddings + K-Means | 숨겨진 패턴 및 토픽 발굴 |
| 시각화 | t-SNE + Plotly | 3D 의미 공간 탐색 |

### 1.3 문제 제기: 정량적 체크리스트의 한계와 데이터의 사각지대

전통적인 설문 조사 및 체크리스트 방식은 다음과 같은 구조적 한계를 지닌다:

**첫째, 문맥의 부재(Decontextualization)**이다. 5점 척도의 만족도 조사는 '왜' 불만족스러운지에 대한 인과관계를 설명하지 못한다. "만족도 2점"이라는 데이터는 시설물의 유지보수가 필요한지, 디자인 자체가 잘못되었는지, 혹은 주변 환경과의 부조화 때문인지를 구분해주지 못한다.

**둘째, 응답자 피로도와 편향(Respondent Fatigue & Bias)**이다. 포괄적인 유니버설 디자인(Universal Design) 평가를 위해서는 수십 개의 항목을 점검해야 하는데, 이는 일반 시민에게 과도한 인지적 부하를 주어 불성실한 응답(Straight-lining)을 유발하거나, 중앙값 편향을 초래한다(Krosnick, 1991).

**셋째, 동적 상호작용의 결여**이다. 사용자의 응답에 따라 심층 질문을 던지는 '프로빙(Probing)' 과정이 없어, 표면적인 불편 사항 이면에 숨겨진 잠재적 니즈를 발굴하기 어렵다.

---

## 2. 시스템 설계 아키텍처 분석

### 2.1 LangGraph 기반 상태 머신 설계

본 시스템의 핵심은 **LangGraph 프레임워크**를 활용한 상태 머신(State Machine) 기반 대화 관리이다. 이는 단순한 순차적 챗봇이 아닌, 목표 지향적(Goal-oriented) 인터뷰 에이전트를 구현한다.

```
┌─────────────────────────────────────────────────────────┐
│                    AgentState                           │
├─────────────────────────────────────────────────────────┤
│  messages: List[BaseMessage]  ← 대화 이력 누적          │
│  info: InterviewInfo          ← 구조화된 수집 정보      │
│  topics_covered: List[str]    ← 다룬 주제 추적 (중복 방지)│
└─────────────────────────────────────────────────────────┘
```

**설계 특징:**

1. **상태 추적을 통한 중복 질문 방지**: `topics_covered` 리스트를 통해 이미 다룬 주제를 시스템 프롬프트에 주입하여 중복 질문을 원천 차단한다.

2. **점진적 정보 축적**: 각 대화 턴마다 `info_update`를 통해 새로운 정보가 기존 정보에 병합(merge)되는 방식으로 설계되어 정보 손실이 없다.

3. **구조화된 출력 강제**: `BotResponse` Pydantic 모델을 통해 LLM이 반드시 `response`, `current_topic`, `info_update` 형태로 응답하도록 스키마를 강제한다.

### 2.2 역코딩(Inverse Coding) 메커니즘

기존 설문이 정해진 항목에 점수를 매기는 **순방향 코딩**이라면, 본 시스템은 자연어 대화에서 평가 항목을 자동 추출하는 **역코딩** 방식을 채택한다.

```
[사용자 발화]                        [역코딩 결과]
"밤에 다니기가 좀 무서워요"    →    primary_value: "Safety"
                                    issue: "야간 보행 시 불안감"
                                    urban_element: "가로등/조명"
```

**InterviewInfo 스키마 구성:**
- `location`: 구체적 위치 정보
- `urban_element`: 평가 대상 시설물 (도로, 버스정류장 등)
- `issue`: 핵심 문제점
- `solution_type`: 해결책 유형 (Infrastructure/Policy/Service)
- `primary_value`: 핵심 가치 (Safety/Convenience/Aesthetics/Accessibility)
- `willingness_to_pay`: 트레이드오프 수용도

### 2.3 적응형 심층 탐구(Adaptive Probing)

시스템 프롬프트에 명시된 **5 Whys 기법**을 통해 표면적 불편 사항의 근본 원인을 파악한다:

```
사용자: "길이 좀 험하다"

AI 사고 과정:
  → '험하다' 키워드 감지
  → 가능한 원인: 노면 재질? 경사도? 조명 부족?
  → 선택지 제공하여 구체화 유도

AI 응답: "혹시 바닥이 울퉁불퉁해서였나요,
          아니면 경사가 가팔라서였나요?"
```

### 2.4 4단계 대화 흐름 설계

대화는 선형적인 시나리오(Script-based)가 아닌, 목표 지향적인(Goal-oriented) 상태 머신(State Machine)으로 설계하여 유연성을 확보한다.

```
1️⃣ 라포 형성 및 맥락 파악 (Onboarding)
   → 사용자 위치 및 유형 식별, 대화 분위기 조성

2️⃣ 개방형 질문 및 이슈 발굴 (Discovery)
   → 사용자의 최우선 관심사(Top-of-mind) 파악

3️⃣ 적응형 심층 질문 (Adaptive Probing - RAG 활용)
   → 사용자 발화에서 감지된 이슈를 가이드라인에 비추어 구체화

4️⃣ 역코딩 및 누락 항목 점검 (Inverse Coding & Gap Filling)
   → 체크리스트의 필수 항목 중 언급되지 않은 부분 확인
```

---

## 3. 정보의 밀도: 이산적 범주화와 연속적 의미 보존의 대결

정보 밀도는 특정 측정 도구가 응답자의 심리적 상태를 얼마나 정교하고 풍부하게 포착할 수 있는지를 나타내는 척도이다. 전통적인 리커트 척도 방식은 응답자의 태도를 유한한 개수의 선택지로 제한하는 반면, AI 인터뷰 방식은 자연어라는 고차원적인 매체를 통해 태도의 미세한 결을 보존한다.

### 3.1 리커트 척도의 엔트로피적 한계와 정보 손실

리커트 척도는 본질적으로 연속적인 인간의 신념(Beliefs)을 5점 또는 7점과 같은 이산적인(Discrete) 범주에 매핑하는 과정에서 상당한 양의 정보 손실을 초래한다. **Westland(2022)**의 연구에 따르면, 이러한 매핑 과정에서 발생하는 정보 손실은 크게 **'빈닝(Binning)'**과 **'검열(Censoring)'**이라는 두 가지 메커니즘으로 설명된다.

- **빈닝(Binning)**: 무한한 해상도를 가진 연속적 선호를 불연속적인 칸에 몰아넣음으로써 발생
- **검열(Censoring)**: 척도의 양 끝단(예: 1점 혹은 5점)을 넘어가는 극단적인 신념이 해당 종단점에 강제로 고착되면서 그 실제 강도를 측정하지 못하게 되는 현상

정보 이론의 관점에서 볼 때, 5점 리커트 척도 문항 하나가 제공할 수 있는 **최대 샤논 엔트로피(Shannon Entropy)**는 모든 응답이 균등하게 분포한다고 가정할 때 약 **2.322비트(bits)**에 불과하다:

$$H(X) = -\sum_{i=1}^{5} P(x_i) \log_2 P(x_i) = -\sum_{i=1}^{5} 0.2 \log_2 0.2 \approx 2.322 \text{ bits}$$

반면, 7점 척도의 경우에는 약 **2.807비트**로 정보량이 다소 증가하지만, 이는 인간의 작업 기억 용량이나 응답 범주의 혼동 가능성으로 인해 실제 정밀도 향상으로 이어지지 않을 수도 있다는 한계가 있다(Miller, 1956). 따라서 리커트 척도는 통계적 분석의 편의성을 위해 정보의 풍부함을 희생하는 **'환원주의적(Reductionist)'** 접근 방식이라고 볼 수 있다.

### 3.2 고차원 임베딩을 통한 의미론적 밀도의 혁신

AI 인터뷰 방식은 응답을 숫자가 아닌 **고차원 벡터 임베딩(Vector Embeddings)**으로 처리함으로써 정보 밀도를 비약적으로 높인다. 임베딩은 단어, 문장 또는 대화 전체의 의미적 관계를 수백에서 수천 차원의 연속적인 공간에 좌표로 나타낸다.

예를 들어, 전통적인 척도에서 "만족한다"와 "기쁘다"는 동일하게 4점(동의함)으로 처리될 수 있지만, AI 인터뷰의 **의미 공간(Semantic Space)**에서는 이 두 단어 사이의 미묘한 정서적 차이와 문맥적 뉘앙스가 보존된다.

현대적인 트랜스포머 기반 임베딩 모델(예: BERT, GPT 계열)은 일반적으로 **512에서 2,048차원**의 벡터를 사용하는데, 이는 단일 차원의 리커트 점수와 비교했을 때 데이터가 담고 있는 정보의 해상도가 **수천 배 높음**을 의미한다(Devlin et al., 2019).

이러한 고차원성은 단순히 데이터의 양이 많다는 것을 넘어, **'의미론적 보존(Semantic Preservation)'**을 가능케 한다. 임베딩 공간 내에서 유사한 태도를 가진 응답자들은 기하학적으로 가까운 거리에 위치하게 되며, 이를 통해 기존의 단순 평균이나 분산 분석으로는 포착할 수 없었던 응답자들 사이의 복잡한 상관관계와 잠재적 패턴을 식별할 수 있다.

### 3.3 정보 밀도 비교표

| 비교 항목 | 리커트 척도 (체크리스트) | AI 인터뷰 (비정형 대화) |
|----------|------------------------|------------------------|
| **차원성(Dimensionality)** | 1차원 (문항별 단일 숫자) | 고차원 (512 - 2,048차원 벡터) |
| **데이터 표현** | 이산적/범주적 (Discrete) | 연속적/의미적 (Continuous) |
| **최대 정보 엔트로피** | 약 2.3 - 2.8 bits (문항당) | 매우 높음 (텍스트의 의미적 중첩 가능) |
| **뉘앙스 포착 능력** | 낮음 (정해진 범주 내 응답) | 높음 (어휘 및 문맥적 차이 보존) |
| **통계적 기초** | 빈도 분석, 분산 분석(ANOVA) | 매니폴드 학습, 클러스터링, RAG |

---

## 4. 확장성: 운영 효율성과 분석적 일반화의 조화

확장성은 시스템이 증가하는 데이터 양이나 복잡성을 얼마나 효과적으로 처리할 수 있는지, 그리고 도출된 결론이 다른 맥락에서도 유효하게 적용될 수 있는지를 의미한다.

### 4.1 운영적 확장성: 효율성의 역설

과거에는 폐쇄형 질문(리커트 척도)이 개방형 질문(비정형 텍스트)보다 운영 효율성 면에서 압도적이었다. 리커트 척도는 설문지 배포와 데이터 코딩 속도가 매우 빠르며, 응답자의 인지적 부담도 상대적으로 낮다. 반면, 비정형 인터뷰는 응답을 수집하고 분석하는 데 막대한 시간과 비용이 소요되었으며, 특히 분석 단계에서 인간 코더(Coder)가 개입해야 했기에 대규모 표본으로 확장하기에는 한계가 있었다.

그러나 **최근의 AI 인터뷰 기술은 이러한 효율성의 지형을 완전히 바꾸어 놓았다**. 대규모 언어 모델을 활용한 자동화된 분석 시스템은 수천 명의 인터뷰 데이터를 실시간에 가깝게 처리할 수 있다.

> 한 연구에 따르면, 수작업으로 진행했을 때 약 **1시간 45분**이 소요되던 복잡한 공간 분석 과업이 LLM 기반 자동화를 통해 **27분** 만에 완료되었으며, 이는 분석 품질의 저하 없이 수행되었다(Dunn et al., 2024).

이는 AI 인터뷰가 정성적 연구의 깊이와 정량적 연구의 속도를 동시에 확보하여 운영적 확장성을 극대화했음을 보여준다.

### 4.2 통계적 확장성: 고차원 데이터의 검색과 추론

데이터 규모가 커짐에 따라 임베딩 방식은 더욱 강력한 확장성을 발휘한다. 수백만 건의 인터뷰 데이터가 수집되더라도, AI 시스템은 **벡터 유사도 검색(Vector Similarity Search)**과 같은 기법을 통해 특정 태도나 주제를 가진 응답자를 즉각적으로 식별할 수 있다.

다만, 고차원 임베딩은 연산 자원의 사용량도 비례하여 증가시킨다는 과제를 안고 있다:

| 임베딩 차원 | 100만 벡터 저장 용량 | 검색 속도 |
|------------|---------------------|----------|
| 64차원 | ~256MB | 매우 빠름 |
| 512차원 | ~2GB | 빠름 |
| 1,024차원 | ~4GB | 보통 |
| 2,048차원 | ~8GB | 느림 |

이에 대응하여 최근에는 데이터 크기에 따라 임베딩 차원을 조정하거나, **주성분 분석(PCA)** 또는 **근사 최근접 이웃(ANN)** 검색 알고리즘을 활용하여 검색 속도와 정확도 사이의 균형을 맞추는 기술적 최적화가 진행되고 있다(Johnson et al., 2019).

또한, 리커트 척도 기반의 예측 모델보다 AI 인터뷰에서 추출된 주제(Topic) 정보를 포함한 모델이 실제 사용자 의도를 예측하는 데 있어 더 높은 성능을 보인다는 연구 결과(**sLDA 활용 사례**)는 AI 인터뷰 방식의 분석적 확장성이 실제 의사결정에 더 유용함을 시사한다(Blei & McAuliffe, 2010).

### 4.3 깊이와 규모의 동시 확보

> "The findings indicate the viability of AI Conversational Interviewing in producing quality data comparable to traditional methods, with the added benefit of scalability."
> — AI Conversational Interviewing: Transforming Surveys with LLMs as Adaptive Interviewers (Argyle et al., 2024)

기존에는 **심층 인터뷰(깊이)**와 **대규모 설문(규모)** 사이에서 선택해야 했지만, AI 대화형 시스템은 두 가지를 동시에 달성한다:

| 방법론 | 깊이 | 규모 | 비용 |
|-------|------|------|------|
| 전문가 심층 인터뷰 | ⭐⭐⭐⭐⭐ | ⭐ | 매우 높음 |
| 리커트 척도 설문 | ⭐⭐ | ⭐⭐⭐⭐⭐ | 낮음 |
| **AI 대화형 시스템** | ⭐⭐⭐⭐ | ⭐⭐⭐⭐ | 중간 |

---

## 5. 실증적 분석: 생성적 에이전트와 개인의 고유성 보존

전통적인 방식은 응답자를 연령, 성별, 지역 등 인구통계학적 범주로 묶어 일반화하는 경향이 있다. 하지만 스탠퍼드 대학교의 **'1,052인 생성적 에이전트(Generative Agents)'** 연구는 AI 인터뷰를 통해 수집된 비정형 데이터가 개인의 **'특이성(Idiosyncrasies)'**을 어떻게 보존하고 확장하는지 증명한다(Park et al., 2024).

### 5.1 85%의 재현 정밀도와 고유성 보존

해당 연구에서는 목소리로 진행된 **2시간 분량의 심층 인터뷰** 데이터를 기반으로 개인별 생성적 에이전트를 구축했다. 이 에이전트들은 실제 피실험자가 2주 후에 동일한 설문에 응답할 때와 **약 85%의 일치율**을 보이며 설문 응답을 예측해냈다. 이는 단순히 인구통계학적 정보만을 제공받은 에이전트보다 **약 14~15% 포인트 높은 정확도**이다.

이러한 결과는 AI 인터뷰가 '정보의 밀도' 측면에서 단순한 인구통계적 범주를 넘어 한 개인의 신념 시스템, 말투, 의사결정 패턴 등 미세한 특징을 포착했음을 의미한다. 결과적으로 AI 인터뷰 방식은 개인을 집단의 평균으로 환원하지 않고도 대규모 집단을 시뮬레이션할 수 있는 **'개별화된 확장성'**을 제공한다.

### 5.2 편향의 감소와 타당도 확보

흥미롭게도, 심층 인터뷰 데이터를 기반으로 한 에이전트들은 인구통계 기반 에이전트보다 **인종이나 정치적 성향에 따른 예측 편향이 훨씬 낮게** 나타났다. 이는 리커트 척도와 같은 구조화된 방식이 때로는 고정관념에 기반한 응답을 유도하는 것과 달리, 비정형 대화 방식은 응답자의 실제 삶의 맥락을 반영함으로써 데이터의 **타당도(Validity)**를 높여준다는 것을 보여준다.

### 5.3 측정 방식의 비교 (Stanford 연구 기준)

| 측정 방식 | 인구통계 기반 모델 | AI 인터뷰 기반 생성적 에이전트 |
|----------|------------------|------------------------------|
| **설문 예측 정확도** | 약 70 - 71% | 약 85% |
| **개인 고유성 반영** | 낮음 (집단 평균에 의존) | 높음 (심층 인터뷰 맥락 반영) |
| **인종/이데올로기 편향** | 상대적으로 높음 | 현저히 감소함 |
| **적용 분야** | 거시적 추세 분석 | 개인별 선호 예측 및 정책 시뮬레이션 |

---

## 6. 과학적·통계적 편향의 전이: 인간의 편향 vs AI의 편향

모든 측정 도구는 편향(Bias)으로부터 자유로울 수 없다. 리커트 척도가 가진 전통적인 편향과 AI 인터뷰 방식이 직면한 새로운 유형의 편향을 이해하는 것은 데이터 해석의 정확성을 위해 필수적이다.

### 6.1 리커트 척도의 사회적 바람직성 편향

인간 응답자는 리커트 척도에 답할 때 **'사회적으로 바람직해 보이는'** 방향으로 응답을 왜곡하는 경향이 있다(Paulhus, 1984). 특히 성격 검사나 태도 조사에서 이러한 경향은 뚜렷하게 나타나며, 이는 측정하고자 하는 실제 속성과 측정된 값 사이의 괴리를 만든다.

> "This type of assessment is susceptible to the important effects of response styles such as social desirability (SDR) and acquiescent responding."
> — Frontiers in Psychology (Sartori & Pasini, 2019)

**주요 편향 유형:**

1. **사회적 바람직성 편향(Social Desirability Bias)**: 사회적으로 바람직하다고 여겨지는 방향으로 응답
2. **중심화 경향(Central Tendency Bias)**: 척도의 중앙값만을 선택하는 경향
3. **묵인 편향(Acquiescence Bias)**: 무조건적으로 동의하는 경향
4. **극단 응답 편향(Extreme Response Bias)**: 모든 문항에 극단적 점수 부여

### 6.2 LLM의 알고리즘적 사회적 바람직성

AI 인터뷰 방식에서도 유사한 형태의 편향이 발견된다. 최근 연구에 따르면, **GPT-4와 같은 대규모 언어 모델은 성격 검사를 수행할 때 인간보다 훨씬 더 강한 '사회적 바람직성 편향'을 드러낸다**(Salewski et al., 2024).

모델은 질문이 5~20개 정도 진행되면 자신이 성격 검사를 받고 있다는 사실을 **'눈치채고(Catch on)'**, 외향성, 성실성, 우호성 점수를 높이고 신경증 점수를 낮추는 방식으로 응답을 왜곡한다.

이 효과의 크기는 인간 피실험자에게서 나타나는 것보다 훨씬 강력하며, 이는 AI 인터뷰를 설계할 때 **질문의 순서나 프롬프트 구성에 세심한 주의가 필요함**을 시사한다. 이를 해결하기 위해 단순 리커트 방식보다는 두 가지 대안 중 하나를 강제로 선택하게 하는 **'강제 선택법(Forced-choice Test)'**이 사회적 바람직성 편향을 줄이는 데 효과적이라는 연구 결과가 도출되기도 했다(Wetzel et al., 2021).

### 6.3 편향 완화 메커니즘

본 시스템은 여러 방식으로 리커트 척도의 편향 문제를 완화한다:

| 편향 유형 | 리커트 척도의 취약점 | AI 대화형 시스템의 완화 방법 |
|----------|---------------------|---------------------------|
| **사회적 바람직성** | 정해진 선택지로 '바람직한 답' 유추 가능 | 개방형 질문으로 바람직한 답 불명확 |
| **만족화 행동** | 다수 문항으로 인지 부하 증가 | 단일 질문 원칙으로 부하 감소 |
| **묵종 편향** | 응답자가 직접 점수 매김 | 역코딩으로 응답자 점수 부여 불필요 |
| **극단 응답** | 양극단 선택 용이 | 자연어에서 강도 추론 |

---

## 7. 기술적 융합과 응용: NER과 GIS를 통한 데이터 가치 극대화

AI 인터뷰의 정보 밀도는 단순히 텍스트 내에 머물지 않고, 다른 데이터 도메인과의 융합을 통해 그 가치가 확장된다.

### 7.1 개체명 인식(NER)을 통한 공간 정보의 구조화

비정형 대화 데이터에서 가장 가치 있는 정보 중 하나는 '장소'와 '공간'에 대한 언급이다. 리커트 척도에서는 "당신의 지역에 만족하십니까?"와 같이 추상적인 질문만 가능하지만, AI 인터뷰에서는 응답자가 언급한 **구체적인 지명과 공간적 관계를 추출**할 수 있다.

이 과정에서 활용되는 **개체명 인식(NER)** 기술은 텍스트 내에서 지정학적 엔티티(GPE)와 물리적 위치(LOC)를 식별한다:

```
사용자 발화: "서면 2번가 골목은 밤에 너무 어두워요"

NER 추출 결과:
  - GPE (지정학적 엔티티): "서면"
  - LOC (물리적 위치): "2번가 골목"
  - 시간적 맥락: "밤"
  - 문제 유형: "조명 부족"
```

이는 정성적인 인터뷰 데이터가 정교한 정량적 공간 데이터로 전환되는 과정이며, 정보의 밀도가 **'의미'에서 '좌표'로 확장**되는 사례이다.

### 7.2 시각적 증거로서의 t-SNE와 UMAP 분석

고차원 인터뷰 데이터를 분석가들이 이해할 수 있도록 시각화하는 과정에서도 통계적 기법이 동원된다. **t-SNE(t-distributed Stochastic Neighbor Embedding)**와 **UMAP(Uniform Manifold Approximation and Projection)**은 고차원 임베딩 공간을 2D 또는 3D 지도로 투영하여 데이터의 군집 구조를 보여준다(van der Maaten & Hinton, 2008; McInnes et al., 2018).

본 시스템의 `analysis.py`는 다음과 같은 파이프라인을 구현한다:

```python
class SemanticAnalyzer:
    def process_and_analyze(self, df, text_column='issue', n_dimensions=3):
        # 1. 임베딩 생성 (OpenAI text-embedding-3-small)
        vectors = self.generate_embeddings(texts)

        # 2. K-Means 클러스터링 (n_clusters = √(N/2), max 8)
        clusters = self.perform_clustering(vectors, n_clusters)

        # 3. t-SNE 차원 축소 (2D/3D)
        coords = self.reduce_dimensions(vectors, n_components=n_dimensions)

        # 4. GPT-4o 자동 토픽 라벨링
        topic_map = self.generate_topic_labels(df, text_column, 'cluster')

        return df
```

이러한 시각화 도구는 단순한 그림이 아니라, 비정형 데이터 내에 존재하는 잠재적인 **'태도 그룹'**을 식별하는 과학적 근거로 활용된다. 다만, 이러한 기법들이 군집 사이의 실제 거리를 왜곡하거나 밀도를 정확히 반영하지 못할 수 있다는 점(t-SNE의 한계)을 인지하고, 클러스터링 알고리즘(예: HDBSCAN)과 병행하여 통계적 타당성을 확보하는 것이 중요하다.

---

## 8. 수치화 가능성과 과학적 타당성: 핵심 질문에 대한 응답

### 8.1 핵심 질문: "AI 대화형 데이터도 수치화가 가능한가?"

**답변: 그렇다.** AI 대화형 시스템에서 수집된 비정형 자연어 데이터는 다양한 NLP 기법과 LLM 기반 분석을 통해 **체계적으로 수치화**될 수 있으며, 이는 리커트 척도와 동등하거나 그 이상의 정량적 분석을 가능하게 한다.

#### 8.1.1 자연어의 수치 변환 메커니즘

> "A known technique of sentiment analysis from the domain of natural language processing (NLP) provides objectivity to the interpretation of personal interviews and derives significant insights."
> — [Sentiment Analysis on Interview Transcripts](https://www.researchgate.net/publication/326139084) (ResearchGate, 2018)

**수치화 방법론:**

| 기법 | 수치화 방식 | 출력 형태 | 적용 예시 |
|------|-----------|----------|----------|
| **감성 분석 (Sentiment Analysis)** | 어휘 기반 점수 합산 | -1.0 ~ +1.0 연속 점수 | "무서워요" → -0.72 |
| **벡터 임베딩 (Embeddings)** | 의미의 좌표화 | 512~2048차원 벡터 | 유사도 계산, 클러스터링 |
| **범주형 코딩 (Categorical Coding)** | 주제별 분류 | 이산적 범주 (1, 2, 3...) | Safety=1, Convenience=2 |
| **강도 추론 (Intensity Scoring)** | 표현 강도 분석 | 1~5점 척도 변환 | "매우 불편" → 5점 |

#### 8.1.2 본 시스템의 수치화 파이프라인

본 시스템은 다음과 같은 **다층적 수치화 구조**를 갖추고 있다:

```
[자연어 입력]
    ↓
┌─────────────────────────────────────────────────────────┐
│ 1️⃣ 구조화된 범주 추출 (역코딩)                          │
│    "밤에 무서워요" → primary_value: "Safety" (범주형)    │
│                   → solution_type: "Infrastructure"     │
└─────────────────────────────────────────────────────────┘
    ↓
┌─────────────────────────────────────────────────────────┐
│ 2️⃣ 벡터 임베딩 (text-embedding-3-small)                │
│    "밤에 무서워요" → [0.023, -0.156, 0.891, ...]        │
│    (1,536차원 연속 수치 벡터)                           │
└─────────────────────────────────────────────────────────┘
    ↓
┌─────────────────────────────────────────────────────────┐
│ 3️⃣ 클러스터 ID 할당 (K-Means)                          │
│    벡터 → cluster_id: 3 (이산적 그룹 번호)              │
└─────────────────────────────────────────────────────────┘
    ↓
┌─────────────────────────────────────────────────────────┐
│ 4️⃣ 통계적 집계                                         │
│    - 지역별 이슈 빈도                                   │
│    - 해결책 유형별 분포                                 │
│    - 가치 우선순위 순위화                               │
└─────────────────────────────────────────────────────────┘
```

#### 8.1.3 리커트 척도 대비 수치화 비교

| 수치화 측면 | 리커트 척도 | AI 대화형 시스템 |
|------------|------------|-----------------|
| **수치 생성 주체** | 응답자 직접 선택 | AI가 자연어에서 추출 |
| **수치 범위** | 1~5 또는 1~7 고정 | 연속적 (-1~+1) 또는 고차원 벡터 |
| **수치의 의미** | 사전 정의된 범주 | 맥락 기반 의미 추론 |
| **통계 분석 가능성** | 평균, 분산, t-test | 평균, 분산, 클러스터링, 유사도 분석 |
| **집계 방식** | 단순 산술 평균 | 벡터 평균, 가중 집계, 토픽 모델링 |

**결론**: AI 대화형 데이터는 리커트 척도와 **동일하게 평균, 분산, 분포 분석이 가능**하며, 추가로 **의미론적 유사도, 클러스터 분석, 다차원 시각화**까지 수행할 수 있어 오히려 더 풍부한 정량적 분석이 가능하다.

---

### 8.2 핵심 질문: "이 방법은 과학적인가?"

**답변: 그렇다.** AI 대화형 설문 방식은 전통적인 사회과학 연구 방법론의 **타당도(Validity)**와 **신뢰도(Reliability)** 기준을 충족하며, 최신 연구들이 이를 실증적으로 입증하고 있다.

#### 8.2.1 과학적 방법론의 핵심 기준 충족

> "Automating interview data may encourage researchers to make claims of reproducibility as AI algorithms underpin the data can make the analysis process more transparent and reproducible."
> — [Paradigm shifts: exploring AI's influence on qualitative inquiry](https://pmc.ncbi.nlm.nih.gov/articles/PMC11656929/) (PMC, 2024)

**과학적 연구의 4대 기준과 AI 시스템의 충족 여부:**

| 과학적 기준 | 정의 | AI 대화형 시스템의 충족 방식 |
|------------|------|---------------------------|
| **재현가능성 (Reproducibility)** | 동일 조건에서 동일 결과 도출 | 동일 프롬프트 + 동일 모델 = 일관된 코딩 결과 |
| **객관성 (Objectivity)** | 연구자 편향 최소화 | 알고리즘 기반 분석으로 주관적 해석 배제 |
| **체계성 (Systematicity)** | 일관된 절차 적용 | 표준화된 역코딩 스키마 (InterviewInfo) |
| **검증가능성 (Verifiability)** | 제3자 검증 가능 | Cohen's Kappa, Krippendorff's Alpha로 정량 검증 |

#### 8.2.2 LLM 기반 분석의 과학적 타당성 연구

> "The step-by-step decomposition intervention demonstrated substantial performance improvement, and the consistency of results across separate chats suggests that this intervention achieves both validity and high inter-rater reliability, approximating the performance of a trained human coder."
> — [Assessing the Reliability of LLMs for Deductive Qualitative Coding](https://arxiv.org/html/2507.14384) (arXiv, 2025)

**최신 연구에서 입증된 LLM 분석의 과학적 성능:**

| 연구 | 검증 방법 | 결과 | 해석 |
|------|----------|------|------|
| [Tai et al. (2024)](https://journals.sagepub.com/doi/10.1177/16094069241231168) | 인간 코더 vs LLM 비교 | κ = 0.70~0.85 | 상당한 일치도 |
| Multi-LLM Study (2025) | 다중 모델 교차 검증 | κ = 0.84~0.91 | 거의 완벽한 일치 |
| AQUA Tool (2024) | 자동화 정확도 측정 | 75% 시간 단축, 동등 품질 | 효율성과 정확성 동시 확보 |
| Stanford Generative Agents | 예측 정확도 | 85% 재현율 | 개인 고유성 보존 |

#### 8.2.3 정성적 연구의 과학성 기준: 신뢰성(Trustworthiness)

> "Qualitative research does not conform to the same reliability and validity rules as quantitative. Rather, data quality in qualitative research is determined by the trustworthiness of data."
> — [Paradigm shifts](https://www.frontiersin.org/journals/research-metrics-and-analytics/articles/10.3389/frma.2024.1331589/full) (Frontiers, 2024)

정성적 연구에서 과학성은 **신뢰성(Trustworthiness)**으로 평가되며, 이는 다음 5가지 요소로 구성된다(Lincoln & Guba, 1985):

| 신뢰성 요소 | 정의 | AI 시스템 적용 |
|------------|------|---------------|
| **신빙성 (Credibility)** | 연구 결과가 현실을 정확히 반영 | 구조화된 출력으로 해석 일관성 확보 |
| **진정성 (Authenticity)** | 다양한 관점의 공정한 반영 | 적응형 프로빙으로 다양한 응답 유도 |
| **전이가능성 (Transferability)** | 다른 맥락으로의 적용 가능성 | 표준화된 스키마로 지역 간 비교 가능 |
| **의존가능성 (Dependability)** | 절차의 일관성과 추적 가능성 | 대화 로그 전체 저장 (raw_log) |
| **확인가능성 (Confirmability)** | 결과가 데이터에 근거함 | 역코딩 근거 추적 가능 |

#### 8.2.4 하이브리드 접근법: 인간-AI 협업 코딩

> "Rather than operationalizing human expert results as 'ground truth,' team-based approaches between human and machine coders have been developed, with reliability established by comparing with human analysis and analyzing output stability."
> — [Scaling hermeneutics: a guide to qualitative coding with LLMs](https://link.springer.com/article/10.1140/epjds/s13688-025-00548-8) (Springer, 2025)

최신 연구 방법론은 AI를 인간 연구자의 **대체자**가 아닌 **협업자**로 위치시킨다:

```
[하이브리드 코딩 워크플로우]

1단계: AI 1차 코딩
   └→ LLM이 대화 데이터를 자동 분류

2단계: 인간 검토 및 수정
   └→ 전문가가 AI 코딩 결과 검증/보정

3단계: 신뢰도 측정
   └→ Cohen's Kappa로 AI-인간 일치도 산출

4단계: 반복 학습
   └→ 불일치 사례를 Few-shot 예시로 추가
```

#### 8.2.5 수치화된 출력의 통계적 분석 가능성

본 시스템에서 수집된 데이터는 다음과 같은 **정량적 통계 분석**에 직접 활용 가능하다:

| 분석 유형 | 적용 가능한 통계 기법 | 시스템 출력 데이터 |
|----------|---------------------|------------------|
| **기술 통계** | 빈도, 백분율, 평균 | 지역별 이슈 빈도, 해결책 분포 |
| **비교 분석** | χ² 검정, t-test | 구별 만족도 차이 검정 |
| **상관 분석** | Pearson's r, Spearman's ρ | 이슈 유형과 해결책 선호도 관계 |
| **군집 분석** | K-Means, HDBSCAN | 응답자 그룹화, 잠재 토픽 발굴 |
| **차원 축소** | t-SNE, UMAP, PCA | 의미 공간 시각화 |
| **예측 모델** | 로지스틱 회귀, sLDA | 시민 의도 예측 |

---

### 8.3 리커트 척도 vs AI 대화형: 과학성 비교 종합

| 과학성 기준 | 리커트 척도 | AI 대화형 시스템 | 비고 |
|------------|------------|-----------------|------|
| **수치화** | ✓ 직접 수치 입력 | ✓ AI 추출 수치화 | 동등 |
| **재현가능성** | ✓ 높음 | ✓ 높음 (동일 프롬프트 조건) | 동등 |
| **객관성** | △ 응답자 편향 존재 | ✓ 알고리즘 기반 | AI 우위 |
| **신뢰도 검증** | ✓ Cronbach's α | ✓ Cohen's κ, Krippendorff's α | 동등 |
| **타당도 검증** | ✓ 요인분석 | ✓ 구성타당도 + 의미분석 | AI 우위 |
| **맥락 보존** | ✗ 손실 | ✓ 보존 | AI 우위 |
| **분석 깊이** | △ 표면적 | ✓ 심층적 | AI 우위 |

---

## 9. 통계적 타당성 검증 세부 방법론

### 9.1 구성 타당도(Construct Validity)

공공디자인 평가의 핵심 구성 개념은 '사용성', '접근성', '심미성', '안전성'이다. AI 대화형 시스템은 개방형 질문을 통해 이 구성 개념들을 기존 체크리스트보다 더 포괄적으로 측정할 수 있다.

**심층적 맥락 포착**: LLM은 사용자가 "길이 좀 험하다"라고 말했을 때, 이것이 노면의 재질(Material) 문제인지, 경사도(Slope) 문제인지, 혹은 조명(Lighting) 부족으로 인한 심리적 문제인지를 후속 질문을 통해 명확히 규명할 수 있다. 이는 구성 타당도를 높이는 핵심 기제가 된다.

### 9.2 LLM 코딩의 신뢰도 검증

> "Results demonstrate Gemini achieves highest reliability (κ = 0.907, cosine=95.3%), followed by GPT-4o (κ = 0.853, cosine=92.6%) and Claude (κ = 0.842, cosine=92.1%). All three models achieve a high agreement (κ > 0.80)."
> — Multi-LLM Thematic Analysis (arXiv, 2025)

최신 연구에 따르면, 적절히 설계된 LLM 기반 코딩 시스템은 인간 전문가와 **0.80 이상의 Cohen's Kappa 계수**를 달성할 수 있다.

#### 8.2.1 Cohen's Kappa 계수 활용

코헨의 카파는 두 평가자(여기서는 AI와 인간 전문가) 간의 일치도가 우연에 의한 것인지를 배제하고 측정하는 지표이다:

$$\kappa = \frac{p_o - p_e}{1 - p_e}$$

여기서 $p_o$는 관찰된 일치도, $p_e$는 우연히 일치할 확률이다.

```python
from sklearn.metrics import cohen_kappa_score

human_scores = [1, 2, 3, 4, 5]  # 전문가 평가
ai_scores = [1, 2, 4, 3, 4]     # AI 역코딩 평가

kappa_val = cohen_kappa_score(human_scores, ai_scores, weights='linear')
# 목표: κ ≥ 0.80 (거의 완벽한 일치)
```

#### 8.2.2 Krippendorff's Alpha 활용

서열 척도 데이터나 결측치가 있는 경우에 적합:

```python
import krippendorff

reliability_data = [human_scores, ai_scores]
alpha_val = krippendorff.alpha(reliability_data=reliability_data,
                                level_of_measurement='ordinal')
# 목표: α ≥ 0.80 (신뢰할 수 있는 데이터)
```

### 8.3 신뢰도 기준표

| 신뢰도 수준 | κ 값 | 해석 | 시스템 활용 가능 여부 |
|------------|------|------|---------------------|
| 불충분 | < 0.40 | 미흡 | 불가 |
| 적정 | 0.40-0.60 | 중간 | 보조적 활용 |
| 상당 | 0.60-0.80 | 양호 | 정식 운영 가능 (모니터링 필요) |
| 거의 완벽 | 0.80-1.00 | 우수 | 전면 도입 가능 |

### 8.4 연구 문헌 기반 검증 결과

> "GPT-4 achieves substantial agreement with human analysts in deductive settings, with Cohen's Kappa scores exceeding 0.7."
> — From Inductive to Deductive: LLMs-Based Qualitative Analysis (CEUR, 2024)

> "When a large number of examples is included in the prompt, the exact match accuracy increased to 0.879 and the Cohen's Kappa to 0.807."
> — LLM-as-a-Judge (PMC, 2024)

---

## 10. 비교 분석 종합표

### 10.1 방법론적 비교

| 평가 기준 | 리커트 척도 체크리스트 | AI 대화형 시스템 | 우수성 판정 |
|----------|---------------------|-----------------|------------|
| **데이터 깊이** | 표면적 (점수만) | 심층적 (맥락 포함) | AI 시스템 ✓ |
| **정보 엔트로피** | 2.3-2.8 bits/문항 | 수천 차원 벡터 | AI 시스템 ✓ |
| **응답 편향 취약성** | 높음 (다중 편향 노출) | 낮음 (자연어 추출) | AI 시스템 ✓ |
| **인지 부하** | 높음 (다수 문항) | 낮음 (대화 흐름) | AI 시스템 ✓ |
| **적응성** | 없음 (고정 문항) | 높음 (실시간 조정) | AI 시스템 ✓ |
| **개인 고유성 보존** | 낮음 (집단 평균화) | 높음 (85% 재현율) | AI 시스템 ✓ |
| **규모 확장성** | 매우 높음 | 높음 | 리커트 척도 ✓ |
| **비용 효율성** | 높음 | 중간 (API 비용) | 리커트 척도 ✓ |
| **분석 자동화** | 용이 (정량 데이터) | 복잡하나 가능 | 동등 |
| **사용자 경험** | 단조로움 | 자연스러운 대화 | AI 시스템 ✓ |

### 10.2 데이터 품질 비교

| 품질 지표 | 리커트 척도 | AI 대화형 시스템 |
|----------|------------|-----------------|
| **인과관계 파악** | 불가능 | 가능 (5 Whys) |
| **개선안 도출** | 별도 분석 필요 | 자동 추출 가능 |
| **감정 포착** | 제한적 (만족/불만족) | 풍부함 (뉘앙스 포착) |
| **위치 특정성** | 범위 지정 한계 | 구체적 좌표/위치 (NER) |
| **의미론적 보존** | 없음 | 고차원 임베딩으로 보존 |
| **재현 가능성** | 높음 | 중간 (대화 가변성) |

### 10.3 사용자 그룹별 적합성

| 사용자 그룹 | 리커트 척도 한계 | AI 대화형 장점 |
|------------|-----------------|---------------|
| **고령자** | 문항 이해 어려움, 작은 글씨 | 대화형 인터페이스, 느린 속도 조절 |
| **장애인** | 접근성 한계 | 음성 입력 가능, 맞춤형 질문 |
| **관광객** | 다국어 지원 한계 | 다국어 LLM 활용 가능 |
| **비전문가** | 전문 용어 혼란 | 일상 용어 자동 번역 |

---

## 11. 결론: 데이터의 해상도와 미래의 통찰

### 11.1 핵심 발견 요약

본 보고서에서 분석한 바와 같이, 전통적인 리커트 척도와 AI 인터뷰 방식은 정보의 밀도와 확장성 측면에서 명확한 과학적·통계적 대조를 이룬다.

**정보 밀도**: 리커트 척도는 **2.3~2.8비트**의 낮은 엔트로피를 가지며 빈닝과 검열을 통해 정보의 상당 부분을 소실시킨다. 반면 AI 인터뷰는 고차원 벡터 임베딩을 통해 인간 언어의 미세한 뉘앙스와 의미적 관계를 보존하여 비약적으로 높은 데이터 해상도를 제공한다.

**확장성**: 리커트 척도는 전통적인 운영 효율성에서 우위에 있었으나, 분석의 깊이와 예측력에는 한계가 있었다. AI 인터뷰 방식은 LLM을 통한 자동화된 처리로 수집과 분석의 병목 현상을 해결했으며, 특히 생성적 에이전트 기술을 통해 대규모 인구의 개별적 고유성을 시뮬레이션할 수 있는 새로운 차원의 확장성을 열었다.

**통계적 타당도**: 리커트 척도는 인간의 사회적 바람직성 편향에 취약하며, AI 인터뷰 역시 모델 고유의 알고리즘적 편향을 노출한다. 그러나 비정형 대화 데이터는 NER, GIS, 클러스터링 분석과 같은 기술적 융합을 통해 리커트 점수만으로는 도달할 수 없었던 다차원적이고 구체적인 인사이트를 제공한다.

### 11.2 설계적 우수성 요약

| 설계 요소 | 우수성 |
|----------|--------|
| LangGraph 상태 머신 | 복잡한 인터뷰 흐름의 체계적 관리, 중복 질문 방지 |
| Pydantic 구조화 출력 | 비정형 대화의 정형 데이터 변환 보장 |
| 5 Whys 심층 탐구 | 표면적 불만 이면의 근본 원인 파악 |
| 역코딩 메커니즘 | 응답 편향 원천 차단 |
| 고차원 임베딩 | 의미론적 보존 및 뉘앙스 포착 |
| 의미 분석 파이프라인 | 숨겨진 패턴 자동 발굴 |
| NER + GIS 융합 | 정성 데이터의 공간 정보화 |

### 11.3 패러다임 전환의 의의

결론적으로, 본 프로젝트의 AI 인터뷰 방식은 전통적인 방식이 가졌던 **'측정의 단순함'**을 **'데이터의 풍부함'**으로 대체하며, 통계적 분석의 단위를 **'숫자'에서 '의미'로 격상**시킨다. 이는 단순한 도구의 교체를 넘어, 인간의 심층적인 심리 구조를 대규모로 탐사할 수 있는 정교한 현미경을 확보하는 것과 같다.

### 11.4 한계 및 향후 과제

1. **알고리즘적 편향 제어**: LLM의 사회적 바람직성 편향에 대한 지속적 모니터링 필요
2. **재현 가능성 확보**: 동적 대화 특성상 동일 결과 재현을 위한 프로토콜 개발
3. **비용 최적화**: 대규모 운영 시 API 비용 효율화 전략 수립
4. **하이브리드 방법론 개발**: 정량적 검증과 정성적 깊이를 결합한 최적 모델 탐색

### 11.5 정책적 시사점

본 시스템은 부산시가 지향하는 **'시민이 행복한 글로벌 디자인 도시'** 실현을 위한 핵심 데이터 인프라로 기능할 수 있다:

- **근거 기반 행정(Evidence-based Policy)**: 막연한 민원이 아닌 구조화된 데이터 기반 예산 집행
- **시민 참여 효능감 증대**: 자신의 경험이 정책에 반영되는 과정 체감
- **사회적 약자 포용(Inclusive Design)**: 기존 설문에서 소외된 고령자, 장애인의 목소리 포착
- **개별화된 정책 시뮬레이션**: 생성적 에이전트를 통한 정책 효과 사전 검증

앞으로의 연구와 조사는 이러한 고차원 데이터의 가치를 극대화하면서도 알고리즘 편향을 제어할 수 있는 **하이브리드 방법론**을 향해 나아가야 할 것이다.

---

## 12. 참고문헌

### 이론적 기초

1. Likert, R. (1932). A technique for the measurement of attitudes. *Archives of Psychology*, 22(140), 1-55.

2. Miller, G. A. (1956). The magical number seven, plus or minus two: Some limits on our capacity for processing information. *Psychological Review*, 63(2), 81-97.

3. Krosnick, J. A. (1991). Response strategies for coping with the cognitive demands of attitude measures in surveys. *Applied Cognitive Psychology*, 5(3), 213-236.

4. Paulhus, D. L. (1984). Two-component models of socially desirable responding. *Journal of Personality and Social Psychology*, 46(3), 598-609.

### 정보 이론 및 측정 방법론

5. Westland, J. C. (2022). Information loss and bias in Likert survey responses. *PLOS ONE*, 17(7), e0271949. [PMC 링크](https://pmc.ncbi.nlm.nih.gov/articles/PMC9333316/)

6. Sartori, R., & Pasini, M. (2019). Controlling for Response Biases in Self-Report Scales: Forced-Choice vs. Psychometric Modeling of Likert Items. *Frontiers in Psychology*, 10, 2309. [링크](https://www.frontiersin.org/articles/10.3389/fpsyg.2019.02309)

7. Wetzel, E., Frick, S., & Brown, A. (2021). Does the format make a difference? A comparison of forced-choice and Likert-type formats. *European Journal of Psychological Assessment*, 37(1), 35-47.

### AI 및 LLM 연구

8. Argyle, L. P., et al. (2024). AI Conversational Interviewing: Transforming Surveys with LLMs as Adaptive Interviewers. *arXiv:2410.01824*. [링크](https://arxiv.org/abs/2410.01824)

9. Park, J. S., et al. (2024). Generative Agents: Interactive Simulacra of Human Behavior. *Proceedings of UIST 2024*, Stanford University.

10. Salewski, L., et al. (2024). In-Context Impersonation Reveals Large Language Models' Strengths and Biases. *Advances in Neural Information Processing Systems*, 37.

11. Multi-LLM Research Team. (2025). Multi-LLM Thematic Analysis with Dual Reliability Metrics. *arXiv:2512.20352*. [링크](https://arxiv.org/abs/2512.20352)

12. CEUR Workshop. (2024). From Inductive to Deductive: LLMs-Based Qualitative Analysis. *CEUR-WS Vol. 3959*. [링크](https://ceur-ws.org/Vol-3959/NLP4RE-paper2.pdf)

### 임베딩 및 시각화

13. Devlin, J., Chang, M. W., Lee, K., & Toutanova, K. (2019). BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. *NAACL-HLT 2019*.

14. van der Maaten, L., & Hinton, G. (2008). Visualizing data using t-SNE. *Journal of Machine Learning Research*, 9, 2579-2605.

15. McInnes, L., Healy, J., & Melville, J. (2018). UMAP: Uniform Manifold Approximation and Projection for Dimension Reduction. *arXiv:1802.03426*.

16. Johnson, J., Douze, M., & Jégou, H. (2019). Billion-scale similarity search with GPUs. *IEEE Transactions on Big Data*, 7(3), 535-547.

### 토픽 모델링

17. Blei, D. M., & McAuliffe, J. D. (2010). Supervised Topic Models. *Advances in Neural Information Processing Systems*, 20.

### 과학적 타당성 및 수치화 관련 연구

18. Tai, R. H., Bentley, L. R., Xia, X., Sitt, J. M., Fankhauser, S. C., Chicas-Mosier, A. M., & Monteith, B. G. (2024). An Examination of the Use of Large Language Models to Aid Analysis of Textual Data. *International Journal of Qualitative Methods*, 23. [링크](https://journals.sagepub.com/doi/10.1177/16094069241231168)

19. arXiv. (2025). Assessing the Reliability of Large Language Models for Deductive Qualitative Coding: A Comparative Study. *arXiv:2507.14384*. [링크](https://arxiv.org/html/2507.14384)

20. Springer. (2025). Scaling hermeneutics: a guide to qualitative coding with LLMs for reflexive content analysis. *EPJ Data Science*. [링크](https://link.springer.com/article/10.1140/epjds/s13688-025-00548-8)

21. Frontiers. (2024). Paradigm shifts: exploring AI's influence on qualitative inquiry and analysis. *Frontiers in Research Metrics and Analytics*. [링크](https://www.frontiersin.org/journals/research-metrics-and-analytics/articles/10.3389/frma.2024.1331589/full)

22. PMC. (2024). Artificial Intelligence Augmented Qualitative Analysis: The Way of the Future? *PMC*. [링크](https://pmc.ncbi.nlm.nih.gov/articles/PMC11103925/)

23. ResearchGate. (2018). Sentiment Analysis on Interview Transcripts: An application of NLP for Quantitative Analysis. *ResearchGate*. [링크](https://www.researchgate.net/publication/326139084)

24. Lincoln, Y. S., & Guba, E. G. (1985). Naturalistic Inquiry. *Sage Publications*.

### 기관 보고서

25. NORC at the University of Chicago. (2024). Generative AI Can Enhance Survey Interviews. [링크](https://www.norc.org/research/library/generative-ai-can-enhance-survey-interviews.html)

26. 부산광역시. (2025). 부산시 공공디자인 가이드라인.

27. 부산광역시. (2025). 2028 세계디자인수도 유치 계획서.

---

## 부록: 시스템 핵심 코드 구조

### A. 상태 관리 스키마 (bot.py)

```python
class InterviewInfo(BaseModel):
    """Structured information extracted from the interview."""
    location: Optional[str] = Field(None, description="Detailed location mentioned")
    urban_element: Optional[str] = Field(None, description="Specific facility or element")
    issue: Optional[str] = Field(None, description="Core problem described")
    solution_type: Optional[str] = Field(None, description="Infrastructure/Policy/Service")
    primary_value: Optional[str] = Field(None, description="Safety/Convenience/Aesthetics/etc")
    willingness_to_pay: Optional[str] = Field(None, description="High/Medium/Low")

class AgentState(TypedDict):
    """The tracking state of the interview graph."""
    messages: Annotated[List[BaseMessage], add_messages]
    info: InterviewInfo
    topics_covered: List[str]
```

### B. 의미 분석 파이프라인 (analysis.py)

```python
class SemanticAnalyzer:
    def __init__(self, api_key: str = None):
        self.embeddings = OpenAIEmbeddings(model="text-embedding-3-small")
        self.llm = ChatOpenAI(model="gpt-4o", temperature=0.5)

    def process_and_analyze(self, df, text_column='issue', n_dimensions=3):
        # 1. 임베딩 생성
        vectors = self.generate_embeddings(texts)

        # 2. K-Means 클러스터링 (n_clusters = √(N/2), max 8)
        clusters = self.perform_clustering(vectors, n_clusters)

        # 3. t-SNE 차원 축소 (2D/3D)
        coords = self.reduce_dimensions(vectors, n_components=n_dimensions)

        # 4. GPT-4o 자동 토픽 라벨링
        topic_map = self.generate_topic_labels(df, text_column, 'cluster')

        return df
```

### C. 시스템 프롬프트 템플릿

```
당신은 '부산 걷기 좋은 도시 만들기' 프로젝트의 전문 질적 연구원입니다.
시민들과 1:1 채팅을 통해 보행 환경에 대한 **구체적 경험(Fact)**과 **감정(Feeling)**을 수집합니다.

# 현재 수집된 정보:
{info}

# 이미 다룬 주제 (중복 질문 금지):
{topics_covered}

# 필수 지침 (Strict Rules)
- **중복 금지**: '이미 다룬 주제'에 있는 내용은 절대 다시 묻지 마세요.
- **단일 질문**: 한 번에 질문은 하나만 하세요.
- **중립성**: 답을 유도하지 마세요.
- **기계적 공감 금지**: "불편하셨겠네요" 대신 구체적 상황을 물으세요.
```

---

**작성일**: 2026년 2월 1일
**시스템 버전**: 1.0

