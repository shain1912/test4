부산시 글로벌 허브 도시 조성을 위한 AI 기반 공공디자인 대화형 평가 시스템 구축 및 타당성 검증 보고서1. 서론: 공공디자인 평가 패러다임의 전환과 부산의 전략적 과제1.1 연구 배경: '글로벌 디자인 도시' 부산의 비전과 현황부산광역시는 '2028 세계디자인수도(WDC)' 유치와 함께 '글로벌 허브 도시'로의 도약을 목표로 도시 전역의 공공디자인 품격을 높이는 데 행정력을 집중하고 있다. 특히 '빅 디자인(Big Design) 프로젝트'를 통해 도시 비우기, 통합하기, 채우기 전략을 추진하며, 시민이 체감할 수 있는 사용자 중심의 디자인 혁신을 꾀하고 있다. 이러한 흐름 속에서 부산시는 버스 정류장, 맨홀 뚜껑, 보행 안내 표지판 등 시민 생활과 밀접한 공공시설물에 대한 표준 디자인 가이드라인을 수립하고, 이를 16개 구·군에 일관성 있게 적용하기 위한 노력을 기울여왔다.그러나 기존의 공공디자인 평가 방식은 전문가 중심의 하향식(Top-down) 점검이나, 제한된 문항으로 구성된 정량적 체크리스트에 의존해 왔다. 이러한 방식은 물리적 규격 준수 여부를 확인하는 데에는 유효하나, 부산의 독특한 지리적 특성(산복도로, 해안가, 신도시 등)과 초고령화 사회로 진입한 인구학적 특성이 반영된 '사용자 경험(UX)'을 심층적으로 포착하는 데에는 한계가 있다. 예를 들어, 산복도로 급경사지에 설치된 벤치의 경우, 물리적 규격은 충족할지라도 고령 사용자가 느끼는 심리적 불안감이나 접근 과정에서의 신체적 부하와 같은 질적 데이터는 기존 체크리스트로는 누락될 가능성이 높다.1.2 문제 제기: 정량적 체크리스트의 한계와 데이터의 사각지대전통적인 설문 조사 및 체크리스트 방식은 다음과 같은 구조적 한계를 지닌다.
첫째, **문맥의 부재(Decontextualization)**이다. 5점 척도의 만족도 조사는 '왜' 불만족스러운지에 대한 인과관계를 설명하지 못한다. "만족도 2점"이라는 데이터는 시설물의 유지보수가 필요한지, 디자인 자체가 잘못되었는지, 혹은 주변 환경과의 부조화 때문인지를 구분해주지 못한다.
둘째, **응답자 피로도와 편향(Respondent Fatigue & Bias)**이다. 포괄적인 유니버설 디자인(Universal Design) 평가를 위해서는 수십 개의 항목을 점검해야 하는데, 이는 일반 시민에게 과도한 인지적 부하를 주어 불성실한 응답(Straight-lining)을 유발하거나, 중앙값 편향을 초래한다.
셋째, 동적 상호작용의 결여이다. 사용자의 응답에 따라 심층 질문을 던지는 '프로빙(Probing)' 과정이 없어, 표면적인 불편 사항 이면에 숨겨진 잠재적 니즈를 발굴하기 어렵다.1.3 연구 목적: AI 대화형 설문 시스템의 도입 필요성본 보고서는 이러한 한계를 극복하기 위해 거대언어모델(LLM) 기반의 'AI 대화형 설문 시스템' 구축 방안을 제안한다. 이 시스템은 부산의 16개 구·군별 지역 특성과 노인, 장애인, 관광객 등 다양한 인간군(Persona)별 특성을 반영하여 능동적으로 인터뷰를 수행한다. 핵심은 비정형 자연어 대화를 실시간으로 분석하여 기존의 표준화된 체크리스트 항목으로 변환하는 '역코딩(Inverse Coding)' 기술이다. 이를 통해 정성적 데이터의 깊이(Thick Data)와 정량적 데이터의 통계적 활용성(Big Data)을 동시에 확보할 수 있다. 본고에서는 시스템의 구체적인 구축 방법론, 과학적/통계적 타당성 검증 방안, 그리고 부산의 행정 환경에 최적화된 챗봇 설계 로직을 상세히 기술한다.2. 이론적 배경 및 과학적 타당성 확보 방안AI가 수행한 정성적 인터뷰 데이터를 행정 의사결정의 근거로 활용하기 위해서는 해당 방법론이 기존의 인간 전문가나 정형 설문조사를 대체할 수 있을 만큼의 신뢰도(Reliability)와 타당도(Validity)를 갖추었는지를 입증해야 한다. 최근 'LLM-as-a-Judge(심판으로서의 LLM)' 연구들은 LLM이 인간 평가자와 매우 높은 수준의 일치도를 보임을 증명하고 있다.2.1 구성 타당도(Construct Validity): 무엇을 측정할 것인가?공공디자인 평가의 핵심 구성 개념은 '사용성', '접근성', '심미성', '안전성'이다. AI 대화형 시스템은 개방형 질문을 통해 이 구성 개념들을 기존 체크리스트보다 더 포괄적으로 측정할 수 있다.심층적 맥락 포착: LLM은 사용자가 "길이 좀 험하다"라고 말했을 때, 이것이 노면의 재질(Material) 문제인지, 경사도(Slope) 문제인지, 혹은 조명(Lighting) 부족으로 인한 심리적 문제인지를 후속 질문을 통해 명확히 규명할 수 있다. 이는 구성 타당도를 높이는 핵심 기제가 된다.유니버설 디자인 7원칙의 적용: 공평한 사용, 사용의 유연성, 간단하고 직관적인 사용 등 유니버설 디자인의 원칙은 단답형 문항보다는 사용자의 실제 경험 서술을 통해 더 정확하게 평가될 수 있다.2.2 통계적 신뢰도 검증: LLM 코딩의 일치도 분석기존 체크리스트를 AI 자동 코딩(Auto-coding)으로 대체할 때의 타당성을 확보하기 위해 다음의 통계적 검증 지표를 필수적으로 적용해야 한다.2.2.1 코헨의 카파(Cohen's Kappa) 계수코헨의 카파는 두 평가자(여기서는 AI와 인간 전문가) 간의 일치도가 우연에 의한 것인지를 배제하고 측정하는 지표이다.검증 목표: AI가 대화 내용을 분석하여 "보행 안전성" 항목을 '부적합(1점)'으로 판정했을 때, 인간 전문가도 동일하게 판정하는지를 검증한다.수용 기준: 일반적으로 카파 계수가 0.60 이상이면 '상당한 일치(Substantial agreement)', 0.80 이상이면 '거의 완벽한 일치(Almost perfect agreement)'로 간주한다. 최신 연구에 따르면, 미세 조정(Fine-tuning)된 LLM은 정성적 데이터 코딩에서 0.80 이상의 카파 계수를 달성할 수 있음이 보고되었다.산출 공식:$$\kappa = \frac{p_o - p_e}{1 - p_e}$$여기서 $p_o$는 관찰된 일치도, $p_e$는 우연히 일치할 확률이다.2.2.2 크리펜도르프의 알파(Krippendorff's Alpha)코헨의 카파가 주로 명목 척도에 사용된다면, 크리펜도르프의 알파는 서열 척도(Likert Scale 등)나 결측치가 있는 데이터에서도 강건한 신뢰도 척도를 제공한다.적용: 1점~5점 척도로 변환된 AI의 평가 점수와 인간 평가자의 점수 간 신뢰도를 측정하는 데 적합하다. 사회과학 연구에서는 통상 $\alpha \ge 0.80$을 신뢰할 수 있는 데이터의 기준으로 삼으며, 0.667 이상이면 잠정적 결론 도출이 가능한 수준으로 본다. 부산시 공공디자인 평가 시스템은 초기 파일럿 단계에서 $\alpha \ge 0.80$ 달성을 목표로 프롬프트를 최적화해야 한다.2.2.3 공존 타당도(Concurrent Validity) 및 예측 타당도상관분석(Correlation Analysis): 기존 체크리스트 설문 결과와 AI 대화형 설문 결과 간의 상관계수(Pearson's r)를 산출하여, 두 도구가 동일한 현상을 측정하고 있음을 입증한다.민감도(Sensitivity) 분석: AI 시스템이 기존 체크리스트보다 안전 위해 요소나 불편 사항을 더 민감하게 탐지해내는지를 비교 분석한다. 예를 들어, 텍스트 마이닝을 통해 도출된 '미끄러짐' 키워드 빈도와 실제 민원 데이터 간의 연관성을 분석함으로써 예측 타당도를 확보할 수 있다.2.3 편향 제거 및 윤리적 타당성한국어 텍스트, 특히 부산 방언이나 구어체에 내재된 뉘앙스를 정확히 파악하는 것은 평가의 공정성에 직결된다.방언 및 존비어 처리: 한국어 특화 LLM(예: HyperCLOVA X) 또는 충분한 한국어 말뭉치로 학습된 모델을 사용하여, "깨끗하네"가 칭찬인지 비꼬는 표현인지 문맥적으로 파악하는 능력이 요구된다.지킬 앤 하이드(Jekyll & Hyde) 검증: 하나의 모델이 평가를 수행하고, 또 다른 모델(적대적 모델)이 해당 평가의 편향성을 비판하게 하는 상호 검증 로직을 도입하여 평가의 객관성을 강화한다.3. 부산 지역 특화 AI 설문 시스템 구축 방법론3.1 권역별/유형별 세분화 전략 (Segmentation Strategy)부산은 해안, 산지, 도심, 신도시가 공존하는 복합적인 도시 구조를 가지고 있다. 획일적인 설문 로직은 지역적 특수성을 반영하지 못하므로, GPS 위치 기반 또는 사용자 선택에 따른 맞춤형 평가 모듈을 가동해야 한다.3.1.1 지리적 권역별 특화 지표 (Busan Zone Typology)권역 구분대상 지역 (예시)주요 공공디자인 평가 중점 사항관련 가이드라인 및 참조원도심/산복도로중구, 동구, 영도구수직 이동성(Vertical Mobility): 급경사지 계단 안전, 핸드레일 견고성, 보행 약자용 쉼터 배치, 공폐가 관리 및 CPTED(범죄예방디자인).부산시 빈집 정비 및 도시재생 가이드라인해양/관광 거점해운대구, 수영구심미성 및 글로벌 수용성: 야간 경관 조명, 다국어 안내 표지판 시인성, 포토존과 자연경관의 조화, 해안 산책로의 내구성(염해 방지).해운대/광안리 야간경관 및 유니버설 디자인스마트 신도시강서구 (에코델타시티)스마트/친환경성: 스마트 쉘터(냉난방) 기능성, 수변 공간 접근성, 생태 면적률, 자율주행 로봇 친화적 보도 포장.에코델타시티 스마트시티 계획 및 수변 공간 가이드라인생활/산업 혼재사상구, 사하구생활 안전 및 환경: 공단 인접 지역의 대기질 안내 사이니지, 보행로와 차도의 분리(안전 펜스), 노후 시설물의 유지관리 상태.부산시 공공시설물 표준 디자인(맨홀, 펜스)3.1.2 인간군별 페르소나 (User Persona) 맞춤형 로직고령자 (Silver Citizen): 부산의 높은 고령화율을 고려하여, 시인성이 높은 UI와 느린 대화 속도를 적용한다. 질문은 추상적인 미학보다는 "걷기에 숨이 차지 않은지", "앉았다 일어날 때 벤치 높이가 적절한지" 등 신체적 부하(Low Physical Effort)에 집중한다.장애인 (Barrier-Free Focus): 휠체어 사용자, 시각 장애인 등을 대상으로 하며, 질문은 부산시 BF 인증 기준에 근거하여 "점자 블록의 연속성", "경사로의 유효 폭" 등을 구체적으로 확인한다.관광객 (Visitor): "길 찾기가 쉬웠는가(Wayfinding)", "부산의 정체성이 느껴지는가" 등 인지적 지도(Cognitive Map) 형성과 경험적 가치를 중점적으로 묻는다.3.2 시스템 아키텍처: RAG 기반 에이전트 시스템단순한 챗봇이 아닌, 검색 증강 생성(RAG) 기술과 에이전트(Agent) 워크플로우를 결합한 지능형 시스템을 구축한다.지식 베이스(Knowledge Base) 구축:부산시 공공디자인 가이드라인(2025), 유니버설 디자인 체크리스트, 도로안전시설 설치 및 관리 지침 등을 PDF/텍스트로 변환하여 벡터 데이터베이스(예: Pinecone, ChromaDB)에 임베딩한다.이때, 'OpenAI text-embedding-3' 또는 한국어에 특화된 네이버 'Clova Embedding' 모델을 사용하여 검색 정확도를 높인다.대화형 에이전트 (Interviewer Agent):사용자의 응답 의도를 파악하고, 지식 베이스에서 관련 규정을 실시간으로 호출(Retrieval)하여 적절한 후속 질문(Follow-up Question)을 생성한다.랭체인(LangChain) 또는 랭그래프(LangGraph) 프레임워크를 사용하여 대화의 상태(State)를 관리하고, 누락된 평가 항목으로 대화를 유도한다.평가/코딩 에이전트 (Coder/Judge Agent):대화 내용을 실시간으로 분석하여 백그라운드에서 체크리스트 항목을 채운다. 사용자가 "경사로가 너무 가팔라서 무서웠다"고 말하면, 이를 항목 4.2 경사로 기울기 -> 점수: 1점(매우 미흡) -> 근거: "무서웠다"는 심리적 공포 표현으로 구조화된 데이터(JSON)로 변환한다.4. 구체적인 챗봇 설계 로직 및 프롬프트 엔지니어링4.1 대화 흐름 설계 (Conversation Flow)대화는 선형적인 시나리오(Script-based)가 아닌, 목표 지향적인(Goal-oriented) 상태 머신(State Machine)으로 설계하여 유연성을 확보한다.1단계: 라포 형성 및 맥락 파악 (Onboarding)목표: 사용자 위치 및 유형 식별, 대화 분위기 조성.로직: GPS 좌표를 수신하거나 지역을 선택받음 -> 해당 지역의 '페르소나' 로드 (예: 원도심 지역이면 친근한 어조).시스템 발화 예시: "안녕하세요! 부산의 걷기 좋은 도시 만들기에 참여해주셔서 감사합니다. 지금 계신 곳은 [영도구 봉래동] 근처시군요. 이곳의 보행 환경에 대해 이야기해 볼까요?"2단계: 개방형 질문 및 이슈 발굴 (Discovery)목표: 사용자의 최우선 관심사(Top-of-mind) 파악.로직: 특정 항목을 먼저 묻지 않고 자유 발화를 유도.시스템 발화 예시: "이곳을 이용하시면서 가장 불편하거나, 혹은 마음에 들었던 점이 있으신가요?"3단계: 적응형 심층 질문 (Adaptive Probing - RAG 활용)목표: 사용자 발화에서 감지된 이슈를 부산시 가이드라인에 비추어 구체화.시나리오:사용자: "밤에 다니기가 좀 무서워요."AI 사고 과정(Chain of Thought): '무서움' 키워드 감지 -> CPTED 가이드라인 검색 -> 조명 조도, 사각지대, CCTV 유무 관련 기준 호출.시스템 발화: "저런, 많이 불안하셨겠어요. 혹시 가로등이 어두워서였나요, 아니면 골목에 숨을 공간이 많아서였나요? CCTV 안내판은 보셨나요?"4단계: 역코딩 및 누락 항목 점검 (Inverse Coding & Gap Filling)목표: 체크리스트의 필수 항목 중 언급되지 않은 부분 확인.로직: 현재까지 수집된 정보로 가상 체크리스트 마킹 -> 미작성된 필수 항목(예: 바닥 포장 상태)에 대해 자연스러운 전환 질문 생성.시스템 발화: "말씀 감사합니다. 혹시 바닥은 어땠나요? 비가 오면 미끄러울 것 같다거나, 걷기에 울퉁불퉁하진 않았나요?"4.2 프롬프트 엔지니어링 전략AI가 부산의 맥락을 이해하고 '전문가'처럼 행동하게 하기 위해 정교한 시스템 프롬프트가 필요하다.시스템 프롬프트 템플릿 (System Prompt Template)역할(Role)당신은 부산광역시의 공공디자인을 평가하는 전문 조사원입니다.시민과의 친근한 대화를 통해 공공시설물의 문제점을 파악하고, 이를 '부산시 공공디자인 가이드라인'에 근거하여 평가해야 합니다.페르소나 설정 (Persona)이름: 부산디자인봇어조: 정중하면서도 친근한 어조 (상대방이 부산 사투리를 쓰면 적절히 반응하여 유대감 형성)태도: 공감적 경청(Active Listening) 후 구체적 사실 확인(Fact-checking)작업 지침 (Instructions)맥락 유지: 사용자가 언급한 특정 위치(예: 산복도로, 해운대 해변)의 지리적 특성을 고려하여 질문하십시오. 산복도로라면 '경사', '계단'에 집중하고, 해운대라면 '관광객 편의', '경관'에 집중하십시오.역코딩 수행: 사용자의 답변을 분석하여 내부적으로 다음 항목을 평가하십시오. (사용자에게 점수를 묻지 말고, 답변 내용으로 추론하십시오)접근성 (Accessibility)안전성 (Safety)편의성 (Convenience)심미성 (Aesthetics)심층 탐색: 사용자가 모호하게 답변(예: "그냥 별로예요")하면, 반드시 "구체적으로 어떤 부분이 불편하셨나요? 재질 때문인가요, 아니면 위치 때문인가요?"와 같이 선택지를 제공하여 구체화를 유도하십시오.제약 사항 (Constraints)한 번에 하나의 질문만 하십시오.전문 용어(예: 조도, 루베, 유효폭) 대신 쉬운 일상 용어(예: 밝기, 넓이)를 사용하십시오.사용자의 개인정보(이름, 전화번호)는 묻지 마십시오.4.3 부산 방언 및 뉘앙스 처리 로직부산 지역 고령층과의 원활한 소통을 위해 방언 처리 모듈이 필수적이다.입력 처리: STT(Speech-to-Text) 또는 텍스트 입력 단계에서 "억수로(매우)", "단디(제대로)", "널짜뿌다(떨어뜨리다)" 등의 어휘를 표준어 의미로 매핑하여 AI가 정확히 이해하도록 한다. 이를 위해 부산 방언 데이터셋으로 미세 조정된 모델이나 프롬프트 내에 '방언 사전(Few-shot examples)'을 포함시킨다.출력 생성: AI의 답변 끝맺음에 "~예", "~입니꺼" 등을 과하지 않게 사용하여 정서적 거리감을 좁히는 '로컬라이제이션(Localization)' 전략을 구사한다.5. 구현 기술 및 운영 프로세스5.1 기술 스택 (Tech Stack)안정적이고 확장 가능한 시스템 구축을 위해 검증된 오픈소스 및 클라우드 기술을 활용한다.프론트엔드 (User Interface):Streamlit (Python): 빠른 프로토타이핑과 데이터 시각화 대시보드 구축에 최적화되어 있다. st.chat_message, st.session_state를 활용하여 대화형 인터페이스를 손쉽게 구현할 수 있다.카카오톡 채널 연동: 한국 내 가장 높은 접근성을 가진 플랫폼인 카카오톡을 통해 설문을 진행하기 위해, 카카오 i 오픈빌더와 Python 백엔드(FastAPI)를 연동한다. 이는 별도 앱 설치 없이 QR코드 스캔만으로 설문에 참여하게 하여 노인층의 진입 장벽을 낮춘다.백엔드 (Logic & Ops):Python (FastAPI): 비동기 처리 및 AI 모델 서빙.LangChain: 에이전트 워크플로우 관리.데이터베이스:Vector DB (FAISS/Chroma): 가이드라인 문서 및 유사 민원 사례 검색용.Relational DB (PostgreSQL): 설문 결과(구조화된 데이터) 및 사용자 메타데이터 저장.5.2 데이터 파이프라인 및 분석 대시보드수집된 대화 데이터는 실시간으로 분석되어 정책 결정자에게 시각화된 정보로 제공되어야 한다.실시간 역코딩(Inverse Coding) 파이프라인:[사용자 발화] -> [LLM 분석] -> [감성 분석 & 카테고리 분류] -> ->.워드 클라우드 및 히트맵:구별/동별 불만 키워드를 지도 위에 히트맵으로 표출.예: "동구 초량동" 클릭 시 -> 주요 불만 키워드 "계단", "가로등", "미끄러짐" 표출.유니버설 디자인 지수(UD Index) 산출:AI가 평가한 항목별 점수를 종합하여 각 공공시설물의 'UD 지수'를 자동 산출하고, 기준 미달 시설물에 대해 '개선 권고' 알림을 담당 공무원에게 발송.5.3 파일럿 테스트 및 단계별 도입 로드맵1단계 (PoC): 에코델타시티 또는 부산역 광장 등 특정 거점을 대상으로 키오스크 및 QR 기반 시범 운영. AI의 평가 결과와 전문가의 현장 평가 결과를 비교하여 일치도(Kappa 계수) 0.8 이상 달성 시까지 모델 튜닝.2단계 (확산): '15분 도시 부산' 생활권 내 주요 보행로로 확대. 구·군청 민원실과 연계하여 시민 의견 수렴 채널로 공식화.3단계 (고도화): 수집된 데이터를 바탕으로 '부산형 공공디자인 예측 모델' 구축. 특정 지역의 인구통계학적 변화에 따라 필요한 공공디자인 요소를 선제적으로 제안.6. 결론 및 제언본 보고서에서 제안하는 **'AI 기반 대화형 공공디자인 평가 시스템'**은 부산이 지향하는 '시민이 행복한 글로벌 디자인 도시'를 실현하기 위한 핵심적인 데이터 인프라이다. 이 시스템은 기존의 정량적 체크리스트가 놓치고 있던 사용자 경험의 맥락과 깊이를 포착할 뿐만 아니라, 통계적으로 타당한 방법론(역코딩 및 일치도 검증)을 통해 행정 데이터로서의 신뢰성을 확보한다.기대 효과:데이터 기반 행정(Evidence-based Policy): 막연한 민원이 아닌, 구체적이고 정량화된 데이터를 근거로 공공디자인 예산을 효율적으로 집행할 수 있다.시민 참여 효능감 증대: 단순한 점수 매기기가 아닌, 자신의 구체적인 경험을 AI가 경청하고 정책에 반영하는 과정을 통해 시민의 시정 참여 만족도가 향상된다.사회적 약자 포용: 고령자, 장애인 등 기존 설문조사에서 소외되기 쉬운 계층의 목소리를 대화라는 자연스러운 인터페이스를 통해 포용(Inclusive Design)한다.결론적으로, 부산시는 이 시스템의 도입을 통해 공공디자인의 평가 체계를 '관리 중심'에서 '사람 중심'으로 혁신하고, 2028 세계디자인수도서의 위상을 기술과 인문학이 융합된 선진 행정 모델로 입증할 수 있을 것이다.[부록] 상세 데이터 및 구현 참조 자료표 1. 인간 코딩과 AI 역코딩 간 신뢰도 검증 예시 (가상 데이터)평가 항목인간 전문가 점수 (평균)AI 역코딩 점수코헨의 카파 (κ)해석접근성 (경사로)2.02.00.85매우 높은 일치 (신뢰 가능)심미성 (조화)3.53.20.62중간 수준 일치 (추가 학습 필요)안전성 (미끄럼)1.01.00.91거의 완벽한 일치 (즉시 활용 가능)정보 인지성4.04.10.78높은 일치 (미세 조정 권장)주: 파일럿 테스트 시 위와 같은 매트릭스를 작성하여 $\kappa < 0.7$인 항목에 대해서는 프롬프트의 평가 기준(Rubric)을 구체화해야 함.표 2. Python 기반 일치도 분석 코드 예시 (Snippets)Pythonimport pandas as pd
from sklearn.metrics import cohen_kappa_score
import krippendorff

# 데이터 예시: 5명의 사용자에 대한 평가 결과
human_scores = [1, 2, 3, 4, 5] # 전문가 평가
ai_scores = [1, 2, 4, 3, 4]    # AI 역코딩 평가

# 1. Cohen's Kappa 계산 (명목/순서형 데이터 간 일치도)
# linear: 순서형 데이터(점수 차이 반영), quadratic: 큰 오차에 가중치
kappa_val = cohen_kappa_score(human_scores, ai_scores, weights='linear')
print(f"Cohen's Kappa: {kappa_val:.3f}")

# 2. Krippendorff's Alpha 계산 (결측치가 있거나 다수의 평가자일 경우)
# 데이터 포맷팅 (평가자 x 아이템)
reliability_data = [human_scores, ai_scores]
alpha_val = krippendorff.alpha(reliability_data=reliability_data, level_of_measurement='ordinal')
print(f"Krippendorff's Alpha: {alpha_val:.3f}")

# 해석 로직
if alpha_val >= 0.8:
    print("시스템 신뢰도 확보: 정식 운영 가능")
elif alpha_val >= 0.667:
    print("잠정적 활용 가능: 지속적인 모니터링 필요")
else:
    print("신뢰도 부족: 프롬프트 개선 및 기준 재설정 필수")
코드 설명: sklearn 라이브러리를 통해 카파 계수를, krippendorff 라이브러리를 통해 알파 계수를 산출하여 AI 모델의 평가 성능을 정량적으로 검증하는 프로세스임.