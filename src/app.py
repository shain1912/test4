import streamlit as st
import os
import sys
import pandas as pd
from dotenv import load_dotenv
from langchain_core.messages import HumanMessage, AIMessage

# Ensure we can import from src
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from src.bot import BusanDesignGraph, InterviewInfo
from src.db import init_db, insert_interview, get_all_interviews
from src.analysis import SemanticAnalyzer
import plotly.express as px

# Load environment variables
load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")

# Initialize DB
# init_db() # Disabled to prevent wiping data on reload

st.set_page_config(page_title="ë¶€ì‚° ê±·ê¸° ì¢‹ì€ ë„ì‹œ - AI ì¸í„°ë·°ì–´", page_icon="ğŸ™ï¸", layout="wide")

st.title("ğŸ™ï¸ ë¶€ì‚° ê±·ê¸° ì¢‹ì€ ë„ì‹œ ë§Œë“¤ê¸° Platform")

tab1, tab2 = st.tabs(["ğŸ’¬ ì¸í„°ë·° (Chat)", "ğŸ“Š ë¶„ì„ ëŒ€ì‹œë³´ë“œ (Dashboard)"])

# --- TAB 1: Chat ---
with tab1:
    st.header("ì‹œë¯¼ ì¸í„°ë·° (AI Interview)")
    st.markdown("ë¶€ì‚°ì˜ ë³´í–‰ í™˜ê²½ì— ëŒ€í•œ ì—¬ëŸ¬ë¶„ì˜ ì†Œì¤‘í•œ ê²½í—˜ì„ ë“¤ë ¤ì£¼ì„¸ìš”.")

    # Initialize Session State
    if "messages" not in st.session_state:
        st.session_state.messages = []
    if "topics_covered" not in st.session_state:
        st.session_state.topics_covered = []
    if "interview_info" not in st.session_state:
        st.session_state.interview_info = InterviewInfo()
    
    # Initialize Graph
    if "bot_graph" not in st.session_state:
        if api_key:
            st.session_state.bot_graph = BusanDesignGraph(api_key=api_key)
            # Add initial greeting
            greeting = "ì•ˆë…•í•˜ì„¸ìš”! ë¶€ì‚°ì˜ ê±·ê¸° ì¢‹ì€ ë„ì‹œ ë§Œë“¤ê¸°ì— ì°¸ì—¬í•´ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤. ì§€ê¸ˆ ê³„ì‹  ê³³ì€ ì–´ë””ì¸ê°€ìš”?"
            st.session_state.messages.append(AIMessage(content=greeting))
        else:
            st.error("API Keyê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")

    # --- Chat Interface ---
    for message in st.session_state.messages:
        role = "user" if isinstance(message, HumanMessage) else "assistant"
        with st.chat_message(role):
            st.markdown(message.content)

    # Helper to process user input (text or button)
    def process_input(user_text):
        st.session_state.messages.append(HumanMessage(content=user_text))
        
        with st.spinner("AIê°€ ì‘ë‹µ ìƒì„± ì¤‘..."):
            current_state = {
                "messages": st.session_state.messages,
                "info": st.session_state.interview_info,
                "turn_index": st.session_state.get("turn_index", 0)
            }
            
            try:
                result = st.session_state.bot_graph.graph.invoke(current_state)
                
                # Update Session State
                st.session_state.messages = result["messages"]
                st.session_state.interview_info = result["info"]
                st.session_state.turn_index = result["turn_index"]
                st.session_state.suggested_replies = result.get("suggested_replies", [])
                
                st.rerun()
            except Exception as e:
                st.error(f"ì˜¤ë¥˜: {e}")

    # 1. Show Buttons if available
    if "suggested_replies" in st.session_state and st.session_state.suggested_replies:
        st.markdown("##### ë‹µë³€ ì„ íƒí•˜ê¸°:")
        cols = st.columns(len(st.session_state.suggested_replies))
        for idx, reply in enumerate(st.session_state.suggested_replies):
            if cols[idx].button(reply, key=f"btn_{len(st.session_state.messages)}_{idx}"):
                process_input(reply)

    # 2. Chat Input (Always available for fallback or open-ended)
    if prompt := st.chat_input("ë‹µë³€ì„ ì…ë ¥í•´ì£¼ì„¸ìš”..."):
        process_input(prompt)

    st.markdown("---")
    if st.button("ì¸í„°ë·° ì¢…ë£Œ ë° ì €ì¥ (Finish & Save)"):
        with st.spinner("ë°ì´í„°ë¥¼ ì €ì¥í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
            # Save to DB
            info_dict = st.session_state.interview_info.dict()
            insert_interview(info_dict)
            st.success("ì†Œì¤‘í•œ ì˜ê²¬ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤! ëŒ€ì‹œë³´ë“œì—ì„œ ê²°ê³¼ë¥¼ í™•ì¸í•´ë³´ì„¸ìš”.")
            
            # Reset
            st.session_state.messages = []
            st.session_state.topics_covered = []
            st.session_state.interview_info = InterviewInfo()
            st.rerun()

# --- TAB 2: Dashboard ---
with tab2:
    st.header("ì‹¤ì‹œê°„ ë°ì´í„° ë¶„ì„ (Real-time Analysis)")
    
    # 1. Load Data
    try:
        from src.db import get_all_interviews
        data = get_all_interviews()
        df = pd.DataFrame(data)
    except Exception as e:
        st.error(f"ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        st.stop()
    
    # 2. Check Empty
    if df.empty:
        st.info("ì•„ì§ ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ì¸í„°ë·° íƒ­ì—ì„œ ì˜ê²¬ì„ ë‚¨ê²¨ì£¼ì„¸ìš”!")
    else:
        # Metrics
        col1, col2, col3 = st.columns(3)
        col1.metric("ì´ ì¸í„°ë·° ìˆ˜", len(df))
        col2.metric("ìµœê·¼ ìˆ˜ì§‘", df['timestamp'].iloc[0] if 'timestamp' in df.columns else "-")
        
        avg_severity = "-"
        if 'severity_score' in df.columns:
            val = pd.to_numeric(df['severity_score'], errors='coerce').mean()
            if not pd.isna(val):
                avg_severity = f"{val:.1f}/4.0"
        col3.metric("í‰ê·  ì‹¬ê°ë„", avg_severity)

        st.divider()

        # Charts
        col_c1, col_c2 = st.columns(2)
        with col_c1:
            st.subheader("ğŸ™ï¸ ì§€ì—­ë³„ ë¶„í¬")
            if 'location_bucket' in df.columns:
                st.bar_chart(df['location_bucket'].value_counts())
        with col_c2:
            st.subheader("ğŸš¨ ì¹´í…Œê³ ë¦¬ë³„ ë¶„í¬")
            if 'primary_category' in df.columns:
                st.bar_chart(df['primary_category'].value_counts())

        # Semantic Analysis Section
        st.divider()
        st.header("ğŸ§  AI ì˜ë¯¸ ë¶„ì„ (Semantic Cluster)")
        
        if st.button("ì‹¬ì¸µ ë¶„ì„ ì‹¤í–‰ (Run Semantic Analysis)"):
            with st.spinner("AIê°€ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ 3D ì§€ë„ë¥¼ ê·¸ë¦¬ê³  ìˆìŠµë‹ˆë‹¤..."):
                analyzer = SemanticAnalyzer(api_key=api_key)
                
                # Compute 3D t-SNE using 'issue_text' (Requesting 3 dimensions explicitly)
                result_df = analyzer.process_and_analyze(df, text_column='issue_text', n_dimensions=3)
                
                # Store result in session state
                st.session_state['analysis_result'] = result_df
                st.success("ë¶„ì„ ì™„ë£Œ!")

        if 'analysis_result' in st.session_state:
            result_df = st.session_state['analysis_result']

            if 'x' in result_df.columns:
                # 1. 3D Chart
                st.markdown("#### ğŸŒ 3D Semantic Space")
                fig_3d = px.scatter_3d(
                    result_df, 
                    x='x', y='y', z='z',
                    color='topic_label',
                    hover_data=['issue_text', 'location_bucket', 'severity_score'],
                    title="ì‹œë¯¼ ì˜ê²¬ 3D êµ°ì§‘ ì§€ë„",
                    template="plotly_dark",
                    height=600
                )
                fig_3d.update_traces(marker=dict(size=5, opacity=0.8, line=dict(width=0)))
                fig_3d.update_layout(showlegend=False, margin=dict(l=0, r=0, b=0, t=0))
                st.plotly_chart(fig_3d, use_container_width=True)

                # 2. Cluster Detail Cards
                st.divider()
                st.header("ğŸ“‘ ìƒì„¸ í† í”½ ë¦¬ìŠ¤íŠ¸ (Topic List)")
                st.info("ğŸ’¡ ìœ„ 3D ì§€ë„ì— í‘œì‹œëœ ìƒ‰ìƒë³„ í† í”½ì˜ ìƒì„¸ ë‚´ìš©ì…ë‹ˆë‹¤.")
                
                unique_labels = sorted(result_df['topic_label'].unique())
                cols = st.columns(2)
                
                for idx, label in enumerate(unique_labels):
                    with cols[idx % 2]:
                        cluster_data = result_df[result_df['topic_label'] == label]
                        count = len(cluster_data)
                        avg_sev = cluster_data['severity_score'].mean() if 'severity_score' in cluster_data.columns else 0
                        
                        with st.container(border=True):
                            st.subheader(f"{label}")
                            m1, m2 = st.columns(2)
                            m1.metric("ì˜ê²¬ ìˆ˜", f"{count}ê±´")
                            m2.metric("í‰ê·  ì‹¬ê°ë„", f"{avg_sev:.1f}")
                            
                            st.markdown("**ì£¼ìš” í‚¤ì›Œë“œ & ì˜ˆì‹œ:**")
                            sample_issues = cluster_data['issue_text'].sample(min(2, count)).tolist()
                            for issue in sample_issues:
                                st.caption(f"- {issue}")

                st.divider()
                st.subheader("ğŸ“Š ì£¼ì œë³„ ë°ì´í„° ë¶„í¬")
                st.bar_chart(result_df['topic_label'].value_counts())
            else:
                st.warning("ë¶„ì„ ê²°ê³¼ê°€ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

        st.divider()
        with st.expander("ì „ì²´ ë°ì´í„° ë¡œê·¸ ë³´ê¸°"):
            st.dataframe(df)
