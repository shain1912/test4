"""
Streamlit application for the AI Interview Platform.
Supports collecting multiple issues and natural language survey configuration.
"""

import streamlit as st
import os
import sys
import pandas as pd
from dotenv import load_dotenv
from langchain_core.messages import HumanMessage, AIMessage

# Ensure we can import from src
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from src.bot import ConfigurableInterviewGraph, InterviewInfo
from src.db import insert_interview, insert_multiple_issues, get_all_interviews, generate_session_id
from src.analysis import SemanticAnalyzer
from src.config_loader import get_config_loader, get_configs_dir, reset_config_loader
from src.survey_generator import SurveyConfigGenerator
from src.knowledge_base import KnowledgeBase, LocationInfo, get_knowledge_base, reset_knowledge_base
import plotly.express as px
import json

# Load environment variables
load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")

# Load configuration
loader = get_config_loader()
ui = loader.load_ui_strings()
topic_config = loader.load_topic_config()
topic_meta = topic_config.get("meta", {})
interview_mode = topic_config.get("interview_mode", "turn_based")

# Page configuration
page_title = f"{loader.get_localized(topic_meta, 'name')} - {ui['page']['title']}"
st.set_page_config(page_title=page_title, page_icon=ui['page']['icon'], layout="wide")

st.title(f"{ui['page']['icon']} {loader.get_localized(topic_meta, 'name')} Platform")

tab1, tab2, tab3, tab4 = st.tabs([
    ui['tabs']['interview'],
    ui['tabs']['dashboard'],
    "âš™ï¸ ì„¤ë¬¸ ì„¤ì •",
    "ğŸ“š ì§€ì‹ ê´€ë¦¬ (RAG)"
])

# --- TAB 1: Chat ---
with tab1:
    st.header(ui['interview']['header'])
    topic_description = loader.get_localized(topic_meta, 'description')
    st.markdown(topic_description)

    # Initialize Session State
    if "messages" not in st.session_state:
        st.session_state.messages = []
    if "interview_info" not in st.session_state:
        st.session_state.interview_info = InterviewInfo()
    if "collected_issues" not in st.session_state:
        st.session_state.collected_issues = []
    if "is_complete" not in st.session_state:
        st.session_state.is_complete = False
    if "session_id" not in st.session_state:
        st.session_state.session_id = generate_session_id()

    # Initialize Graph
    if "bot_graph" not in st.session_state:
        if api_key:
            st.session_state.bot_graph = ConfigurableInterviewGraph(api_key=api_key)
            greeting = st.session_state.bot_graph.get_greeting()
            st.session_state.messages.append(AIMessage(content=greeting))
        else:
            st.error(ui['interview']['api_key_error'])

    # Sidebar: Show collected issues (field_based mode)
    if interview_mode == "field_based":
        with st.sidebar:
            st.subheader("ğŸ“‹ ìˆ˜ì§‘ëœ ì´ìŠˆ")

            if st.session_state.collected_issues:
                for i, issue in enumerate(st.session_state.collected_issues, 1):
                    with st.expander(f"âœ… ì´ìŠˆ {i}: {issue.get('issue_text', '')[:30]}...", expanded=False):
                        st.write(f"**ë‚´ìš©:** {issue.get('issue_text', '-')}")
                        st.write(f"**ì‹¬ê°ë„:** {issue.get('severity_score', '-')}")
                        st.write(f"**ì¹´í…Œê³ ë¦¬:** {issue.get('primary_category', '-')}")
                        st.write(f"**ìœ„ì¹˜:** {issue.get('location_bucket', '-')}")

            st.divider()
            st.subheader("ğŸ”„ í˜„ì¬ ì´ìŠˆ")
            info = st.session_state.interview_info
            info_dict = info.model_dump()

            required_fields = topic_config.get("required_fields", [])
            for field in required_fields:
                field_id = field["id"]
                field_name = field.get("name", {}).get(loader.language, field_id)
                value = info_dict.get(field_id)

                if value is not None:
                    st.success(f"âœ… {field_name}")
                else:
                    st.warning(f"â³ {field_name}")

            st.metric("ì´ ìˆ˜ì§‘ëœ ì´ìŠˆ", f"{len(st.session_state.collected_issues)}ê±´")

            if st.session_state.is_complete:
                st.balloons()
                st.info("ğŸ‰ ì¸í„°ë·°ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")

    # Chat Interface
    for message in st.session_state.messages:
        role = "user" if isinstance(message, HumanMessage) else "assistant"
        with st.chat_message(role):
            st.markdown(message.content)

    def process_input(user_text):
        st.session_state.messages.append(HumanMessage(content=user_text))

        with st.spinner(ui['interview']['ai_spinner']):
            current_state = {
                "messages": st.session_state.messages,
                "info": st.session_state.interview_info,
                "collected_issues": st.session_state.collected_issues,
                "turn_index": st.session_state.get("turn_index", 0),
                "is_complete": st.session_state.get("is_complete", False)
            }

            try:
                result = st.session_state.bot_graph.graph.invoke(current_state)
                st.session_state.messages = result["messages"]
                st.session_state.interview_info = result["info"]
                st.session_state.collected_issues = result.get("collected_issues", [])
                st.session_state.turn_index = result.get("turn_index", 0)
                st.session_state.suggested_replies = result.get("suggested_replies", [])
                st.session_state.is_complete = result.get("is_complete", False)
                st.rerun()
            except Exception as e:
                st.error(ui['errors']['general'].format(error=e))

    if st.session_state.is_complete:
        total = len(st.session_state.collected_issues)
        st.success(f"âœ… ì¸í„°ë·°ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! ì´ {total}ê°œì˜ ì´ìŠˆê°€ ìˆ˜ì§‘ë˜ì—ˆìŠµë‹ˆë‹¤.")

    if not st.session_state.is_complete:
        if "suggested_replies" in st.session_state and st.session_state.suggested_replies:
            st.markdown(ui['interview']['suggested_replies_label'])
            cols = st.columns(len(st.session_state.suggested_replies))
            for idx, reply in enumerate(st.session_state.suggested_replies):
                if cols[idx].button(reply, key=f"btn_{len(st.session_state.messages)}_{idx}"):
                    process_input(reply)

    if not st.session_state.is_complete:
        if prompt := st.chat_input(ui['interview']['input_placeholder']):
            process_input(prompt)

    st.markdown("---")

    button_type = "primary" if st.session_state.is_complete else "secondary"
    col1, col2 = st.columns([3, 1])

    with col1:
        if st.button(ui['interview']['finish_button'], type=button_type):
            with st.spinner(ui['interview']['saving_spinner']):
                all_issues = list(st.session_state.collected_issues)
                current_info = st.session_state.interview_info.model_dump()
                if current_info.get("issue_text"):
                    all_issues.append(current_info)

                if all_issues:
                    session_id = insert_multiple_issues(all_issues, st.session_state.session_id)
                    st.success(f"âœ… {len(all_issues)}ê°œì˜ ì´ìŠˆê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
                else:
                    st.warning("ì €ì¥í•  ì´ìŠˆê°€ ì—†ìŠµë‹ˆë‹¤.")

                st.session_state.messages = []
                st.session_state.interview_info = InterviewInfo()
                st.session_state.collected_issues = []
                st.session_state.is_complete = False
                st.session_state.session_id = generate_session_id()
                for key in ["turn_index", "suggested_replies", "bot_graph"]:
                    if key in st.session_state:
                        del st.session_state[key]
                st.rerun()

    with col2:
        total = len(st.session_state.collected_issues)
        if st.session_state.interview_info.issue_text:
            total += 1
        st.metric("ì´ìŠˆ ìˆ˜", f"{total}ê±´")

# --- TAB 2: Dashboard ---
with tab2:
    st.header(ui['dashboard']['header'])

    try:
        data = get_all_interviews()
        df = pd.DataFrame(data)
    except Exception as e:
        st.error(ui['dashboard']['data_load_error'].format(error=e))
        st.stop()

    if df.empty:
        st.info(ui['dashboard']['no_data'])
    else:
        col1, col2, col3, col4 = st.columns(4)
        col1.metric(ui['dashboard']['total_interviews'], len(df))

        if 'session_id' in df.columns:
            unique_sessions = df['session_id'].nunique()
            col2.metric("ì´ ì„¸ì…˜ ìˆ˜", unique_sessions)
        else:
            col2.metric(ui['dashboard']['recent_collection'], df['timestamp'].iloc[0] if 'timestamp' in df.columns else "-")

        avg_severity = "-"
        if 'severity_score' in df.columns:
            val = pd.to_numeric(df['severity_score'], errors='coerce').mean()
            if not pd.isna(val):
                avg_severity = f"{val:.1f}/4.0"
        col3.metric(ui['dashboard']['avg_severity'], avg_severity)

        if 'session_id' in df.columns:
            issues_per_session = len(df) / max(df['session_id'].nunique(), 1)
            col4.metric("ì„¸ì…˜ë‹¹ í‰ê·  ì´ìŠˆ", f"{issues_per_session:.1f}ê±´")

        st.divider()

        col_c1, col_c2 = st.columns(2)
        with col_c1:
            st.subheader(ui['dashboard']['location_distribution'])
            if 'location_bucket' in df.columns:
                location_counts = df['location_bucket'].value_counts()
                if not location_counts.empty:
                    st.bar_chart(location_counts)
        with col_c2:
            st.subheader(ui['dashboard']['category_distribution'])
            if 'primary_category' in df.columns:
                category_counts = df['primary_category'].value_counts()
                if not category_counts.empty:
                    st.bar_chart(category_counts)

        st.divider()
        st.header(ui['dashboard']['semantic_analysis_header'])

        if st.button(ui['dashboard']['run_analysis_button']):
            with st.spinner(ui['dashboard']['analysis_spinner']):
                analyzer = SemanticAnalyzer(api_key=api_key)
                result_df = analyzer.process_and_analyze(df, text_column='issue_text', n_dimensions=3)
                st.session_state['analysis_result'] = result_df
                st.success(ui['dashboard']['analysis_complete'])

        if 'analysis_result' in st.session_state:
            result_df = st.session_state['analysis_result']

            if 'x' in result_df.columns:
                st.markdown(ui['dashboard']['semantic_space_title'])
                fig_3d = px.scatter_3d(
                    result_df, x='x', y='y', z='z', color='topic_label',
                    hover_data=['issue_text', 'location_bucket', 'severity_score'],
                    title=ui['dashboard']['chart_title'], template="plotly_dark", height=600
                )
                fig_3d.update_traces(marker=dict(size=5, opacity=0.8, line=dict(width=0)))
                fig_3d.update_layout(showlegend=False, margin=dict(l=0, r=0, b=0, t=0))
                st.plotly_chart(fig_3d, use_container_width=True)

                st.divider()
                st.header(ui['dashboard']['topic_list_header'])

                unique_labels = sorted(result_df['topic_label'].unique())
                cols = st.columns(2)

                for idx, label in enumerate(unique_labels):
                    with cols[idx % 2]:
                        cluster_data = result_df[result_df['topic_label'] == label]
                        count = len(cluster_data)
                        avg_sev = cluster_data['severity_score'].mean() if 'severity_score' in cluster_data.columns else 0

                        with st.container(border=True):
                            st.subheader(f"{label}")
                            m1, m2 = st.columns(2)
                            m1.metric(ui['dashboard']['opinion_count'], f"{count}{ui['dashboard']['opinion_count_unit']}")
                            m2.metric(ui['dashboard']['avg_severity_label'], f"{avg_sev:.1f}")

                            sample_issues = cluster_data['issue_text'].dropna().sample(min(2, count)).tolist()
                            for issue in sample_issues:
                                st.caption(f"- {issue}")

                st.bar_chart(result_df['topic_label'].value_counts())
            else:
                st.warning(ui['dashboard']['analysis_insufficient'])

        st.divider()
        with st.expander(ui['dashboard']['full_data_log']):
            st.dataframe(df)

# --- TAB 3: Survey Configuration ---
with tab3:
    st.header("âš™ï¸ ì„¤ë¬¸ ì„¤ì • ìƒì„±ê¸°")
    st.markdown("""
    **ìì—°ì–´ë¡œ ì„¤ë¬¸ì„ ì„¤ëª…í•˜ë©´ AIê°€ ì„¤ì • íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤.**

    ì˜ˆì‹œ:
    - "ì¹´í˜ ê³ ê° ë§Œì¡±ë„ ì¡°ì‚¬ë¥¼ í•˜ê³  ì‹¶ì–´. ìŒë£Œ ë§›, ì„œë¹„ìŠ¤, ê°€ê²©ì— ëŒ€í•œ ì˜ê²¬ì„ ìˆ˜ì§‘í•˜ê³  1-5ì  ë§Œì¡±ë„ë„ ë°›ê³  ì‹¶ì–´."
    - "íšŒì‚¬ ì§ì›ë“¤ì˜ ê·¼ë¬´ í™˜ê²½ì— ëŒ€í•œ í”¼ë“œë°±ì„ ìˆ˜ì§‘í•˜ê³  ì‹¶ì–´. ë¶ˆí¸í•œ ì , ê°œì„  ìš”ì²­ì‚¬í•­, ë¶€ì„œ ì •ë³´ë¥¼ ë°›ê³  ì‹¶ì–´."
    """)

    # Show current active topic
    st.info(f"ğŸ“Œ í˜„ì¬ í™œì„± ì„¤ë¬¸: **{loader.get_localized(topic_meta, 'name')}** (`{loader.active_topic}`)")

    # List existing topics
    topics_dir = get_configs_dir() / "topics"
    existing_topics = [f.stem for f in topics_dir.glob("*.yaml")]

    with st.expander("ğŸ“ ê¸°ì¡´ ì„¤ë¬¸ ëª©ë¡"):
        for topic in existing_topics:
            is_active = "âœ…" if topic == loader.active_topic else ""
            st.write(f"{is_active} `{topic}`")

    st.divider()

    # Survey description input
    st.subheader("1ï¸âƒ£ ì„¤ë¬¸ ì„¤ëª… ì…ë ¥")
    survey_description = st.text_area(
        "ì–´ë–¤ ì„¤ë¬¸ì„ ë§Œë“¤ê³  ì‹¶ì€ì§€ ììœ ë¡­ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”:",
        height=150,
        placeholder="ì˜ˆ: ëŒ€í•™êµ í•™ìƒë“¤ì˜ ìº í¼ìŠ¤ ìƒí™œ ë§Œì¡±ë„ë¥¼ ì¡°ì‚¬í•˜ê³  ì‹¶ì–´. ì‹œì„¤, ìˆ˜ì—…, êµí†µ í¸ì˜ì„±ì— ëŒ€í•œ ì˜ê²¬ì„ ìˆ˜ì§‘í•˜ê³ , í•™ë…„ê³¼ ì „ê³µë„ ì•Œê³  ì‹¶ì–´."
    )

    # Generate button
    if st.button("ğŸ¤– AIë¡œ ì„¤ë¬¸ ì„¤ì • ìƒì„±", type="primary", disabled=not survey_description):
        if not api_key:
            st.error("API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        else:
            with st.spinner("AIê°€ ì„¤ë¬¸ ì„¤ì •ì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                try:
                    generator = SurveyConfigGenerator(api_key=api_key)
                    config = generator.generate_config(survey_description)
                    st.session_state['generated_config'] = config
                    st.session_state['generated_yaml'] = generator.config_to_yaml(config)
                    st.success("âœ… ì„¤ë¬¸ ì„¤ì •ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!")
                except Exception as e:
                    st.error(f"ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

    # Show generated config
    if 'generated_config' in st.session_state:
        st.divider()
        st.subheader("2ï¸âƒ£ ìƒì„±ëœ ì„¤ë¬¸ ì„¤ì • í™•ì¸")

        config = st.session_state['generated_config']

        col1, col2 = st.columns(2)
        with col1:
            st.markdown(f"**ì„¤ë¬¸ ID:** `{config.topic_id}`")
            st.markdown(f"**ì„¤ë¬¸ ì´ë¦„:** {config.name_ko}")
        with col2:
            st.markdown(f"**ì¹´í…Œê³ ë¦¬ ìˆ˜:** {len(config.categories)}ê°œ")
            st.markdown(f"**ìˆ˜ì§‘ í•„ë“œ ìˆ˜:** {len(config.required_fields)}ê°œ")

        # Preview tabs
        preview_tab1, preview_tab2, preview_tab3 = st.tabs(["ğŸ“‹ ìš”ì•½", "ğŸ“ YAML ë¯¸ë¦¬ë³´ê¸°", "âœï¸ ìˆ˜ì •"])

        with preview_tab1:
            st.markdown("#### ì¸ì‚¬ë§")
            st.info(config.greeting_ko)

            st.markdown("#### ì¹´í…Œê³ ë¦¬")
            for cat in config.categories:
                st.write(f"- **{cat.label_ko}** (`{cat.id}`)")

            st.markdown("#### ìˆ˜ì§‘ í•„ë“œ")
            for field in config.required_fields:
                field_type_label = {"text": "í…ìŠ¤íŠ¸", "scale": "ì²™ë„", "category": "ì„ íƒ"}.get(field.field_type, field.field_type)
                st.write(f"- **{field.name_ko}** ({field_type_label}): {field.description_ko}")

        with preview_tab2:
            st.code(st.session_state['generated_yaml'], language='yaml')

        with preview_tab3:
            st.markdown("**ì„¤ë¬¸ ID ìˆ˜ì •:**")
            new_topic_id = st.text_input("Topic ID", value=config.topic_id, key="edit_topic_id")

            st.markdown("**ì„¤ë¬¸ ì´ë¦„ ìˆ˜ì •:**")
            new_name_ko = st.text_input("ì´ë¦„ (í•œêµ­ì–´)", value=config.name_ko, key="edit_name_ko")

            st.markdown("**ì¸ì‚¬ë§ ìˆ˜ì •:**")
            new_greeting = st.text_area("ì¸ì‚¬ë§", value=config.greeting_ko, key="edit_greeting")

            if st.button("ìˆ˜ì • ì‚¬í•­ ì ìš©"):
                config.topic_id = new_topic_id
                config.name_ko = new_name_ko
                config.greeting_ko = new_greeting
                st.session_state['generated_config'] = config
                generator = SurveyConfigGenerator(api_key=api_key)
                st.session_state['generated_yaml'] = generator.config_to_yaml(config)
                st.success("ìˆ˜ì • ì‚¬í•­ì´ ì ìš©ë˜ì—ˆìŠµë‹ˆë‹¤.")
                st.rerun()

        st.divider()
        st.subheader("3ï¸âƒ£ ì €ì¥ ë° ì ìš©")

        col1, col2 = st.columns(2)

        with col1:
            if st.button("ğŸ’¾ ì„¤ì • íŒŒì¼ ì €ì¥", type="primary"):
                try:
                    generator = SurveyConfigGenerator(api_key=api_key)
                    file_path = generator.save_config(config)
                    st.success(f"âœ… ì €ì¥ ì™„ë£Œ: `{file_path}`")
                except Exception as e:
                    st.error(f"ì €ì¥ ì¤‘ ì˜¤ë¥˜: {e}")

        with col2:
            if st.button("ğŸš€ ì €ì¥í•˜ê³  ë°”ë¡œ ì ìš©"):
                try:
                    generator = SurveyConfigGenerator(api_key=api_key)
                    file_path = generator.save_config(config)
                    generator.update_main_config(config.topic_id)

                    # Reset config loader to reload
                    reset_config_loader()

                    # Clear interview state
                    for key in list(st.session_state.keys()):
                        if key not in ['generated_config', 'generated_yaml']:
                            del st.session_state[key]

                    st.success(f"âœ… ì €ì¥ ë° ì ìš© ì™„ë£Œ! ìƒˆ ì„¤ë¬¸: **{config.name_ko}**")
                    st.info("í˜ì´ì§€ë¥¼ ìƒˆë¡œê³ ì¹¨í•˜ë©´ ìƒˆ ì„¤ë¬¸ì´ ì ìš©ë©ë‹ˆë‹¤.")
                    st.rerun()
                except Exception as e:
                    st.error(f"ì˜¤ë¥˜: {e}")

    # Quick switch existing topic
    st.divider()
    st.subheader("ğŸ”„ ê¸°ì¡´ ì„¤ë¬¸ìœ¼ë¡œ ì „í™˜")

    selected_topic = st.selectbox(
        "í™œì„±í™”í•  ì„¤ë¬¸ ì„ íƒ:",
        options=existing_topics,
        index=existing_topics.index(loader.active_topic) if loader.active_topic in existing_topics else 0
    )

    if st.button("ì´ ì„¤ë¬¸ìœ¼ë¡œ ì „í™˜"):
        try:
            generator = SurveyConfigGenerator(api_key=api_key)
            generator.update_main_config(selected_topic)
            reset_config_loader()

            for key in list(st.session_state.keys()):
                del st.session_state[key]

            st.success(f"âœ… `{selected_topic}` ì„¤ë¬¸ìœ¼ë¡œ ì „í™˜ë˜ì—ˆìŠµë‹ˆë‹¤!")
            st.rerun()
        except Exception as e:
            st.error(f"ì˜¤ë¥˜: {e}")

# --- TAB 4: Knowledge Management (RAG) ---
with tab4:
    st.header("ğŸ“š ì§€ì‹ ë² ì´ìŠ¤ ê´€ë¦¬")
    st.markdown("""
    **RAG (Retrieval Augmented Generation) ì§€ì‹ ê´€ë¦¬**

    ì¸í„°ë·°ì–´ AIê°€ ìœ„ì¹˜/ì‹œì„¤ì— ëŒ€í•œ ë°°ê²½ ì§€ì‹ì„ ê°€ì§€ê³  ë” ìŠ¤ë§ˆíŠ¸í•œ ì§ˆë¬¸ì„ í•  ìˆ˜ ìˆë„ë¡ ì •ë³´ë¥¼ ë“±ë¡í•©ë‹ˆë‹¤.
    ì˜ˆ: "ë¶€ì‚°ëŒ€í•™êµëŠ” ê²½ì‚¬ê°€ ì‹¬í•˜ë‹¤" â†’ AIê°€ ê²½ì‚¬ ê´€ë ¨ í›„ì† ì§ˆë¬¸ì„ ìœ ë„
    """)

    # Initialize knowledge base
    if 'knowledge_base' not in st.session_state:
        try:
            st.session_state.knowledge_base = get_knowledge_base(api_key)
        except Exception as e:
            st.error(f"ì§€ì‹ ë² ì´ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            st.stop()

    kb = st.session_state.knowledge_base

    # Sub-tabs for knowledge management
    kb_tab1, kb_tab2, kb_tab3, kb_tab4 = st.tabs([
        "ğŸ“‹ ë“±ë¡ëœ ì§€ì‹",
        "â• ìƒˆ í•­ëª© ì¶”ê°€",
        "ğŸ“ íŒŒì¼ ì—…ë¡œë“œ",
        "ğŸ” ê²€ìƒ‰ í…ŒìŠ¤íŠ¸"
    ])

    # --- KB Tab 1: View existing knowledge ---
    with kb_tab1:
        st.subheader("ë“±ë¡ëœ ìœ„ì¹˜/ì‹œì„¤ ì •ë³´")

        if not kb.knowledge_data:
            st.info("ë“±ë¡ëœ ì§€ì‹ì´ ì—†ìŠµë‹ˆë‹¤. ìƒ˜í”Œ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ê±°ë‚˜ ìƒˆ í•­ëª©ì„ ì¶”ê°€í•˜ì„¸ìš”.")
            if st.button("ğŸ”„ ìƒ˜í”Œ ë°ì´í„° ë¡œë“œ (ë¶€ì‚° ì§€ì—­)"):
                from src.knowledge_base import create_sample_knowledge_base
                st.session_state.knowledge_base = create_sample_knowledge_base(api_key)
                st.session_state.knowledge_base.save()
                st.success("ìƒ˜í”Œ ë°ì´í„°ê°€ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤!")
                st.rerun()
        else:
            # Display knowledge entries
            for name, info in kb.knowledge_data.items():
                with st.expander(f"ğŸ“ {name} ({info.type} - {info.region})", expanded=False):
                    col1, col2 = st.columns(2)

                    with col1:
                        st.markdown("**íŠ¹ì„±:**")
                        for char in info.characteristics:
                            st.write(f"- {char}")

                        if info.demographics:
                            st.markdown(f"**ì£¼ ì´ìš©ì:** {info.demographics}")

                    with col2:
                        if info.known_issues:
                            st.markdown("**ì•Œë ¤ì§„ ë¬¸ì œ:**")
                            for issue in info.known_issues:
                                st.write(f"- âš ï¸ {issue}")

                        if info.additional_info:
                            st.markdown(f"**ì¶”ê°€ ì •ë³´:** {info.additional_info}")

                    # Delete button
                    if st.button(f"ğŸ—‘ï¸ ì‚­ì œ", key=f"delete_{name}"):
                        del kb.knowledge_data[name]
                        kb.save()
                        st.success(f"'{name}' í•­ëª©ì´ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.")
                        st.rerun()

            st.divider()
            st.metric("ì´ ë“±ë¡ í•­ëª©", f"{len(kb.knowledge_data)}ê°œ")

            # Save button
            if st.button("ğŸ’¾ ë³€ê²½ì‚¬í•­ ì €ì¥"):
                kb.save()
                st.success("ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")

    # --- KB Tab 2: Add new entry ---
    with kb_tab2:
        st.subheader("ìƒˆ ìœ„ì¹˜/ì‹œì„¤ ì •ë³´ ì¶”ê°€")

        with st.form("add_knowledge_form"):
            col1, col2 = st.columns(2)

            with col1:
                name = st.text_input("ìœ„ì¹˜/ì‹œì„¤ ì´ë¦„ *", placeholder="ì˜ˆ: ì„œë©´ì—­")
                location_type = st.selectbox(
                    "ìœ í˜• *",
                    ["ì§€í•˜ì² ì—­", "ëŒ€í•™êµ", "ê´€ê´‘ì§€", "ìƒê¶Œ", "ê³µì›", "ë³‘ì›", "êµí†µì‹œì„¤", "ì£¼ê±°ì§€ì—­", "ê¸°íƒ€"]
                )
                region = st.text_input("ì§€ì—­êµ¬ *", placeholder="ì˜ˆ: ë¶€ì‚°ì§„êµ¬")

            with col2:
                characteristics = st.text_area(
                    "ì£¼ìš” íŠ¹ì„± (ì‰¼í‘œë¡œ êµ¬ë¶„) *",
                    placeholder="ì˜ˆ: ìœ ë™ì¸êµ¬ ë§ìŒ, ìƒì—…ì§€êµ¬, êµí†µ í—ˆë¸Œ"
                )
                known_issues = st.text_area(
                    "ì•Œë ¤ì§„ ë¬¸ì œì  (ì‰¼í‘œë¡œ êµ¬ë¶„)",
                    placeholder="ì˜ˆ: í˜¼ì¡í•œ ë³´í–‰ë¡œ, ë¶ˆë²• ì£¼ì •ì°¨"
                )

            demographics = st.text_input("ì£¼ ì´ìš©ìì¸µ", placeholder="ì˜ˆ: ì§ì¥ì¸, ì‡¼í•‘ê°")
            additional_info = st.text_area("ì¶”ê°€ ì •ë³´", placeholder="ì˜ˆ: 1í˜¸ì„  2í˜¸ì„  í™˜ìŠ¹ì—­")

            submitted = st.form_submit_button("â• ì¶”ê°€", type="primary")

            if submitted:
                if not name or not location_type or not region or not characteristics:
                    st.error("í•„ìˆ˜ í•­ëª©(*)ì„ ëª¨ë‘ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                else:
                    try:
                        new_info = LocationInfo(
                            name=name,
                            type=location_type,
                            region=region,
                            characteristics=[c.strip() for c in characteristics.split(",") if c.strip()],
                            known_issues=[i.strip() for i in known_issues.split(",") if i.strip()] if known_issues else [],
                            demographics=demographics if demographics else None,
                            additional_info=additional_info if additional_info else None
                        )
                        kb.add_location(new_info)
                        kb.save()
                        st.success(f"âœ… '{name}' í•­ëª©ì´ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤!")
                        st.rerun()
                    except Exception as e:
                        st.error(f"ì¶”ê°€ ì‹¤íŒ¨: {e}")

    # --- KB Tab 3: File upload ---
    with kb_tab3:
        st.subheader("íŒŒì¼ì—ì„œ ì§€ì‹ ë¡œë“œ")

        st.markdown("""
        **ì§€ì› í˜•ì‹:**
        - **JSON**: ì•„ë˜ í˜•ì‹ì˜ ë°°ì—´
        - **CSV**: ì»¬ëŸ¼ëª…ì´ ë™ì¼í•œ CSV íŒŒì¼

        ```json
        [
          {
            "name": "ë¶€ì‚°ì—­",
            "type": "êµí†µì‹œì„¤",
            "region": "ë™êµ¬",
            "characteristics": ["KTX ì •ì°¨ì—­", "ëŒ€ì¤‘êµí†µ í—ˆë¸Œ"],
            "known_issues": ["ë³µì¡í•œ ë™ì„ ", "ë…¸ìˆ™ì ë¬¸ì œ"],
            "demographics": "ì—¬í–‰ê°, ì¶œì¥ì",
            "additional_info": "ë¶€ì‚°ì˜ ê´€ë¬¸"
          }
        ]
        ```
        """)

        uploaded_file = st.file_uploader(
            "JSON ë˜ëŠ” CSV íŒŒì¼ ì—…ë¡œë“œ",
            type=["json", "csv"]
        )

        if uploaded_file:
            try:
                if uploaded_file.name.endswith('.json'):
                    data = json.load(uploaded_file)
                    st.write(f"**ë¡œë“œëœ í•­ëª© ìˆ˜:** {len(data)}ê°œ")

                    # Preview
                    with st.expander("ë¯¸ë¦¬ë³´ê¸°"):
                        for item in data[:3]:
                            st.json(item)
                        if len(data) > 3:
                            st.write(f"... ì™¸ {len(data) - 3}ê°œ")

                    if st.button("ğŸ“¥ ì´ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°", key="import_json"):
                        for item in data:
                            info = LocationInfo(**item)
                            kb.add_location(info)
                        kb.save()
                        st.success(f"âœ… {len(data)}ê°œ í•­ëª©ì„ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤!")
                        st.rerun()

                elif uploaded_file.name.endswith('.csv'):
                    df = pd.read_csv(uploaded_file)
                    st.write(f"**ë¡œë“œëœ í–‰ ìˆ˜:** {len(df)}ê°œ")
                    st.dataframe(df.head())

                    if st.button("ğŸ“¥ ì´ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°", key="import_csv"):
                        # Save temporarily and use kb's csv loader
                        import tempfile
                        with tempfile.NamedTemporaryFile(mode='w', suffix='.csv', delete=False) as f:
                            df.to_csv(f.name, index=False)
                            kb.load_from_csv(f.name)
                        kb.save()
                        st.success(f"âœ… {len(df)}ê°œ í•­ëª©ì„ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤!")
                        st.rerun()

            except Exception as e:
                st.error(f"íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")

        st.divider()

        # Export current data
        st.subheader("í˜„ì¬ ë°ì´í„° ë‚´ë³´ë‚´ê¸°")

        if kb.knowledge_data:
            export_data = [info.model_dump() for info in kb.knowledge_data.values()]
            export_json = json.dumps(export_data, ensure_ascii=False, indent=2)

            st.download_button(
                "ğŸ“¤ JSONìœ¼ë¡œ ë‚´ë³´ë‚´ê¸°",
                data=export_json,
                file_name="knowledge_base_export.json",
                mime="application/json"
            )

    # --- KB Tab 4: Search test ---
    with kb_tab4:
        st.subheader("RAG ê²€ìƒ‰ í…ŒìŠ¤íŠ¸")
        st.markdown("""
        ì‚¬ìš©ìê°€ íŠ¹ì • ìœ„ì¹˜ë¥¼ ì–¸ê¸‰í–ˆì„ ë•Œ AIê°€ ì–´ë–¤ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë°›ê²Œ ë˜ëŠ”ì§€ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.
        """)

        test_query = st.text_input(
            "í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬",
            placeholder="ì˜ˆ: ë¶€ì‚°ëŒ€í•™êµ ê·¼ì²˜ì—ì„œ ê±¸ì„ ë•Œ ë¶ˆí¸í–ˆì–´ìš”"
        )

        if st.button("ğŸ” ê²€ìƒ‰", disabled=not test_query):
            if not kb.vector_store:
                st.warning("ë²¡í„° ìŠ¤í† ì–´ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë¨¼ì € ì§€ì‹ì„ ì¶”ê°€í•˜ì„¸ìš”.")
            else:
                with st.spinner("ê²€ìƒ‰ ì¤‘..."):
                    try:
                        # Direct similarity search
                        docs = kb.search(test_query, k=3)

                        st.markdown("### ğŸ“„ ìœ ì‚¬ë„ ê²€ìƒ‰ ê²°ê³¼")
                        if docs:
                            for i, doc in enumerate(docs, 1):
                                with st.expander(f"ê²°ê³¼ {i}: {doc.metadata.get('name', 'Unknown')}"):
                                    st.text(doc.page_content)
                        else:
                            st.info("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")

                        # Context generation
                        st.markdown("### ğŸ¤– AIì—ê²Œ ì „ë‹¬ë  ì»¨í…ìŠ¤íŠ¸")
                        context = kb.get_context_for_location(test_query)

                        if context:
                            st.success(f"**ê°ì§€ëœ ìœ„ì¹˜:** {context.location_name}")

                            st.markdown("**ê´€ë ¨ ì •ë³´:**")
                            for info in context.relevant_info:
                                st.text(info)

                            st.markdown("**ì œì•ˆë˜ëŠ” í›„ì† ì§ˆë¬¸:**")
                            for probe in context.suggested_probes:
                                st.write(f"- ğŸ’¡ {probe}")
                        else:
                            st.info("ê´€ë ¨ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

                    except Exception as e:
                        st.error(f"ê²€ìƒ‰ ì˜¤ë¥˜: {e}")

        st.divider()

        # RAG status
        st.subheader("ğŸ“Š RAG ìƒíƒœ")
        col1, col2, col3 = st.columns(3)

        with col1:
            st.metric("ë“±ë¡ëœ ìœ„ì¹˜", f"{len(kb.knowledge_data)}ê°œ")
        with col2:
            vector_status = "âœ… í™œì„±" if kb.vector_store else "âŒ ë¹„í™œì„±"
            st.metric("ë²¡í„° ìŠ¤í† ì–´", vector_status)
        with col3:
            rag_enabled = topic_config.get("enable_rag", True)
            rag_status = "âœ… í™œì„±" if rag_enabled else "âŒ ë¹„í™œì„±"
            st.metric("RAG ëª¨ë“œ", rag_status)

        # Reset knowledge base
        st.divider()
        if st.button("ğŸ”„ ì§€ì‹ ë² ì´ìŠ¤ ì´ˆê¸°í™”", type="secondary"):
            reset_knowledge_base()
            if 'knowledge_base' in st.session_state:
                del st.session_state['knowledge_base']
            st.success("ì§€ì‹ ë² ì´ìŠ¤ê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
            st.rerun()
