import streamlit as st
import pandas as pd
import sqlite3
import os
import sys

# Ensure proper path for imports
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from src.db import get_all_interviews, DB_PATH
from src.analysis import SemanticAnalyzer
import plotly.express as px

st.set_page_config(page_title="ë¶€ì‚° ê±·ê¸° ì¢‹ì€ ë„ì‹œ - ì¸í„°ë·° ë³´ë“œ", layout="wide")

st.title("ğŸš¶ ë¶€ì‚° ê±·ê¸° ì¢‹ì€ ë„ì‹œ ë§Œë“¤ê¸° - ì‹œë¯¼ ì¸í„°ë·° í˜„í™©")
st.markdown("ì‹œë¯¼ë“¤ê³¼ì˜ 1:1 ì±„íŒ… ì¸í„°ë·°ë¥¼ í†µí•´ ìˆ˜ì§‘ëœ ë³´í–‰ í™˜ê²½ ë°ì´í„°ì…ë‹ˆë‹¤.")

# 1. Load Data
try:
    data = get_all_interviews()
    df = pd.DataFrame(data)
except Exception as e:
    st.error(f"ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    st.stop()

# 2. Check Empty
if df.empty:
    st.warning("ì•„ì§ ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    st.stop()

# 3. Metrics
col1, col2, col3 = st.columns(3)
col1.metric("ì´ ì¸í„°ë·° ìˆ˜", len(df))
col2.metric("ìµœê·¼ ìˆ˜ì§‘", df['timestamp'].iloc[0] if 'timestamp' in df.columns else "-")

avg_severity = "-"
if 'severity_score' in df.columns:
    val = pd.to_numeric(df['severity_score'], errors='coerce').mean()
    if not pd.isna(val):
        avg_severity = f"{val:.1f}/4.0"
col3.metric("í‰ê·  ì‹¬ê°ë„", avg_severity)

st.divider()

# 4. Charts
col_c1, col_c2 = st.columns(2)

with col_c1:
    st.subheader("ğŸ™ï¸ ì§€ì—­ë³„ ë¶„í¬")
    if 'location_bucket' in df.columns:
        loc_counts = df['location_bucket'].value_counts()
        st.bar_chart(loc_counts)
    else:
        st.info("ì§€ì—­ ë°ì´í„° ì—†ìŒ")

with col_c2:
    st.subheader("ğŸ’¡ ì¹´í…Œê³ ë¦¬ë³„ ë¶„í¬")
    if 'primary_category' in df.columns:
        cat_counts = df['primary_category'].value_counts()
        st.bar_chart(cat_counts)
    else:
        st.info("ì¹´í…Œê³ ë¦¬ ë°ì´í„° ì—†ìŒ")

st.divider()

# 5. Data Table
st.subheader("ğŸ“‹ ìƒì„¸ ì¸í„°ë·° ë¡œê·¸")

# Display key columns safely
available_cols = df.columns.tolist()
target_cols = ['id', 'timestamp', 'location_bucket', 'primary_category', 'issue_text', 'severity_score']
display_cols = [c for c in target_cols if c in available_cols]

st.dataframe(df[display_cols], use_container_width=True)

# Expander for full details
with st.expander("ìƒì„¸ ë°ì´í„° ë³´ê¸° (JSON)"):
    selected_id = st.number_input("ID ì…ë ¥", min_value=1, max_value=len(df), step=1)
    if 'id' in df.columns:
        row = df[df['id'] == selected_id]
        if not row.empty:
            st.json(row.to_dict(orient='records')[0])

st.divider()

# 6. Semantic Analysis (Optional)
st.header("ğŸ§  AI ì˜ë¯¸ ë¶„ì„ (Semantic Analysis)")
st.markdown("ë°ì´í„°ì˜ ì˜ë¯¸ë¥¼ ë¶„ì„í•˜ì—¬ ìë™ìœ¼ë¡œ í† í”½ì„ ë¶„ë¥˜í•˜ê³  ì‹œê°í™”í•©ë‹ˆë‹¤.")

if st.button("ë¶„ì„ ì‹¤í–‰ (Analyze)"):
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        st.error("API Key not found in environment.")
    else:
        with st.spinner("AI ë¶„ì„ ì¤‘..."):
            try:
                analyzer = SemanticAnalyzer(api_key=api_key)
                # Use 'issue_text' column for clustering
                target_text_col = 'issue_text' if 'issue_text' in df.columns else 'issue'
                
                result_df = analyzer.process_and_analyze(df, text_column=target_text_col, n_dimensions=3)
                
                if 'x' in result_df.columns:
                    st.success("ë¶„ì„ ì™„ë£Œ!")
                    
                    fig = px.scatter(
                        result_df, 
                        x='x', 
                        y='y', 
                        color='topic_label',
                        hover_data=[target_text_col, 'location_bucket', 'severity_score'],
                        title="ì´ìŠˆ ì˜ë¯¸ ì—°ê²°ë§ (Semantic Network)",
                        template="plotly_white"
                    )
                    st.plotly_chart(fig, use_container_width=True)
                    
                if 'x' in result_df.columns:
                    st.success("ë¶„ì„ ì™„ë£Œ!")
                    
                    # 1. 3D/2D Chart
                    fig = px.scatter_3d(
                        result_df, 
                        x='x', y='y', z='z',
                        color='topic_label',
                        hover_data=[target_text_col, 'location_bucket', 'severity_score'],
                        title="ì´ìŠˆ ì˜ë¯¸ ì—°ê²°ë§ (3D Semantic Network)",
                        template="plotly_white",
                        opacity=0.8
                    )
                    fig.update_traces(marker=dict(size=6, line=dict(width=1, color='DarkSlateGrey')))
                    fig.update_layout(
                        height=600, 
                        showlegend=False, # Hide small legend as requested
                        scene=dict(
                            xaxis=dict(showticklabels=False, title=''),
                            yaxis=dict(showticklabels=False, title=''),
                            zaxis=dict(showticklabels=False, title=''),
                        ),
                        margin=dict(l=0, r=0, b=0, t=40)
                    )
                    st.plotly_chart(fig, use_container_width=True)
                    
                    # 2. Cluster Detail Cards (The "Text Legend")
                    st.divider()
                    st.header("ğŸ“‘ ìƒì„¸ í† í”½ ë¦¬ìŠ¤íŠ¸ (Topic List)")
                    st.info("ğŸ’¡ ìœ„ 3D ì§€ë„ì— í‘œì‹œëœ ìƒ‰ìƒë³„ í† í”½ì˜ ìƒì„¸ ë‚´ìš©ì…ë‹ˆë‹¤.")
                    
                    unique_labels = sorted(result_df['topic_label'].unique())
                    
                    # Create a color map or just list them clearly
                    cols = st.columns(2) # 2 columns layout
                    
                    for idx, label in enumerate(unique_labels):
                        with cols[idx % 2]:
                            cluster_data = result_df[result_df['topic_label'] == label]
                            count = len(cluster_data)
                            avg_sev = cluster_data['severity_score'].mean() if 'severity_score' in cluster_data.columns else 0
                            
                            with st.container(border=True):
                                st.subheader(f"{label}")
                                m1, m2 = st.columns(2)
                                m1.metric("ì˜ê²¬ ìˆ˜", f"{count}ê±´")
                                m2.metric("í‰ê·  ì‹¬ê°ë„", f"{avg_sev:.1f}")
                                
                                st.markdown("**ì£¼ìš” í‚¤ì›Œë“œ & ì˜ˆì‹œ:**")
                                # Get simple samples
                                sample_issues = cluster_data[target_text_col].sample(min(2, count)).tolist()
                                for issue in sample_issues:
                                    st.caption(f"- {issue}")

                    # 3. Summary Chart
                    st.divider()
                    st.subheader("ğŸ“Š í† í”½ ë¹„ì¤‘")
                    st.bar_chart(result_df['topic_label'].value_counts())
                else:
                    st.warning("ë¶„ì„í•  í…ìŠ¤íŠ¸ ë°ì´í„°ê°€ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            except Exception as e:
                st.error(f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
